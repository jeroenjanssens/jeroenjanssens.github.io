<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<link rel="icon" href="/favicon.png" type="image/png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<title>7 command-line tools for data science</title>
		<meta name="viewport" content="width=device-width">
		<meta name="description" content="Dutch Data Scientist in Old New Amsterdam">
		<link href="/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css" />
		<link rel="alternate" type="application/rss+xml" title="Jeroen Janssens" href="http://www.jeroenjanssens.com/feed.xml">
		<meta name="twitter:card" content="summary">
		<meta name="twitter:site" content="@jeroenhjanssens">
		<meta name="twitter:domain" content="jeroenjanssens.com">
		<meta name="twitter:creator" content="@jeroenhjanssens">
		
		  <meta name="twitter:title" content="7 command-line tools for data science">
		
		
		<meta name="twitter:url" content="http://www.jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html">
		
		
		  <meta name="twitter:description" content="In this post I would like to share seven command-line tools that I have found useful in my day-to-day work as data scientist. The tools are: jq, json2csv, csvkit, scrape, xml2json, sample, and Rio.">
		
		
		  <meta name="twitter:image:src" content="http://www.jeroenjanssens.com/img/iris.png">
		
		<meta name="bitly-verification" content="f2828a63ca29"/>
	</head>
	<body>
		<script>
		  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		  ga('create', 'UA-43246574-1', 'jeroenjanssens.com');
		  ga('send', 'pageview');
		</script>
		<div id="site">
			<div id="header">
				<h1><a href="/">Jeroen Janssens</a></h1>
				<div id="description">Dutch Data Scientist in Old New Amsterdam</div>
				<div id="social">
					<ul>
						<li><a href="http://twitter.com/jeroenhjanssens/">Twitter</a></li>
						<li><a href="http://github.com/jeroenjanssens/">Github</a></li>
						<li><a href="http://www.linkedin.com/in/jeroenjanssens">LinkedIn</a></li>
						<li><a href="http://www.jeroenjanssens.com/feed.xml">RSS</a></li>
					<ul>
				</div>
			</div>
			<div id="content">
									<h2>7 command-line tools for data science</h2>
					<div class="date">Published on 19 September 2013</div>
					<a href="https://twitter.com/share" class="twitter-share-button" data-via="jeroenhjanssens">Tweet</a>
					<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
					<div class="post">
						<p><em>Update (7-12-2013) You can now easily install these seven command-line tools with the <a href="http://jeroenjanssens.com/2013/12/07/lean-mean-data-science-machine.html">Data Science Toolbox virtual environment</a>.</em></p>

<p>Data science is <a href="http://www.dataists.com/2010/09/a-taxonomy-of-data-science/">OSEMN</a> (pronounced as awesome).
That is, it involves Obtaining, Scrubbing, Exploring, Modeling, and iNterpreting data.
As a data scientist, I spend quite a bit of time on the command-line, especially when there&#39;s data to be obtained, scrubbed, or explored. And I&#39;m not alone in this.
Recently, <a href="http://www.gregreda.com/2013/07/15/unix-commands-for-data-science/">Greg Reda discussed</a> how the classics (e.g., head, cut, grep, sed, and awk) can be used for data science. Prior to that, Seth Brown discussed how to perform basic <a href="http://www.drbunsen.org/explorations-in-unix/">exploratory data analysis in Unix</a>.</p>

<p>I would like to continue this discussion by sharing seven command-line tools that I have found useful in my day-to-day work. 
The tools are:
<a href="http://stedolan.github.io/jq/">jq</a>,
<a href="https://github.com/jehiah/json2csv">json2csv</a>,
<a href="https://github.com/onyxfish/csvkit">csvkit</a>,
scrape,
<a href="https://github.com/parmentf/xml2json">xml2json</a>,
sample, and Rio. (The home-made tools <code>scrape</code>, <code>sample</code>, and <code>Rio</code> can be found in this <a href="https://github.com/jeroenjanssens/data-science-toolbox">data science toolbox</a>.) Any suggestions, questions, comments, and even pull requests are more than welcome.
(Tools suggested by others can be found towards the bottom of the post.)
OSEMN, let&#39;s get started with our first tool: <code>jq</code>.</p>

<h3>1. jq - sed for JSON</h3>

<p>JSON is becoming an increasingly common data format, especially as APIs are appearing everywhere. I remember cooking up the ugliest <code>grep</code> and <code>sed</code> incantations in order to process JSON. Thanks to <code>jq</code>, those days are now in the past. </p>

<p>Imagine we&#39;re interested in the candidate totals of the 2008 presidential election. It so happens that the New York Times has a <a href="http://developer.nytimes.com/docs/campaign_finance_api/">Campaign Finance API</a>. (You can <a href="http://developer.nytimes.com/apps/mykeys">get your own API keys</a> if you want to access any of their APIs.) Let&#39;s get some JSON using <code>curl</code>:</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">curl -s <span class="s1">&#39;http://api.nytimes.com/svc/elections/us/v3/finances/2008/president/totals.json?api-key=super-secret&#39;</span> &gt; nyt.json
</code></pre></div>
<p>where <code>-s</code> puts <code>curl</code> in silent mode. In its simplest form, i.e., <code>jq &#39;.&#39;</code>, the tool transforms the incomprehensible API response we got:</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">{&quot;status&quot;:&quot;OK&quot;,&quot;base_uri&quot;:&quot;http://api.nytimes.com/svc/elections/us/v3/finances/2008/&quot;,&quot;cycle&quot;:2008,&quot;copyright&quot;:&quot;Copyright (c) 2013 The New York Times Company. All Rights Reserved.&quot;,&quot;results&quot;:[{&quot;candidate_name&quot;:&quot;Obama, Barack&quot;,&quot;name&quot;:&quot;Barack Obama&quot;,&quot;party&quot;:&quot;D&quot;,
</code></pre></div>
<p>into nicely indented and colored output:</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">&lt; nyt.json jq <span class="s1">&#39;.&#39;</span> <span class="p">|</span> head
</code></pre></div><div class="highlight"><pre><code class="json language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&quot;results&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&quot;candidate_id&quot;</span><span class="p">:</span> <span class="s2">&quot;P80003338&quot;</span><span class="p">,</span>
      <span class="nt">&quot;date_coverage_from&quot;</span><span class="p">:</span> <span class="s2">&quot;2007-01-01&quot;</span><span class="p">,</span>
      <span class="nt">&quot;date_coverage_to&quot;</span><span class="p">:</span> <span class="s2">&quot;2008-11-24&quot;</span><span class="p">,</span>
      <span class="nt">&quot;candidate_name&quot;</span><span class="p">:</span> <span class="s2">&quot;Obama, Barack&quot;</span><span class="p">,</span>
      <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Barack Obama&quot;</span><span class="p">,</span>
      <span class="nt">&quot;party&quot;</span><span class="p">:</span> <span class="s2">&quot;D&quot;</span><span class="p">,</span> 
</code></pre></div>
<p>Note that the output isn&#39;t necessarily in the same order as the input.
Besides pretty printing, <code>jq</code> can also select, filter, and format JSON data, as illustrated by 
the following command, which returns the name, cash, and party of each candidate that had at least $1,000,000 in cash:</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">&lt; nyt.json jq -c <span class="s1">&#39;.results[] | {name, party, cash: .cash_on_hand} | select(.cash | tonumber &gt; 1000000)&#39;</span> 
</code></pre></div><div class="highlight"><pre><code class="json language-json" data-lang="json"><span class="p">{</span><span class="nt">&quot;cash&quot;</span><span class="p">:</span><span class="s2">&quot;29911984.0&quot;</span><span class="p">,</span><span class="nt">&quot;party&quot;</span><span class="p">:</span><span class="s2">&quot;D&quot;</span><span class="p">,</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;Barack Obama&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;cash&quot;</span><span class="p">:</span><span class="s2">&quot;32812513.75&quot;</span><span class="p">,</span><span class="nt">&quot;party&quot;</span><span class="p">:</span><span class="s2">&quot;R&quot;</span><span class="p">,</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;John McCain&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;cash&quot;</span><span class="p">:</span><span class="s2">&quot;4428347.5&quot;</span><span class="p">,</span><span class="nt">&quot;party&quot;</span><span class="p">:</span><span class="s2">&quot;D&quot;</span><span class="p">,</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;John Edwards&quot;</span><span class="p">}</span>
</code></pre></div>
<p>Please refer to the <a href="http://stedolan.github.io/jq/manual/">jq manual</a> to read about the many other things it can do, but don&#39;t expect it to solve all your data munging problems. 
Remember, the Unix philosophy favors small programs that do one thing and do it well. 
And <code>jq</code>&#39;s functionality is more than sufficient I would say! 
Now that we have the data we need, it&#39;s time to move on to our second tool: <code>json2csv</code>.</p>

<h3>2. json2csv - convert JSON to CSV</h3>

<p>While JSON is a great format for interchanging data, it&#39;s rather unsuitable for most command-line tools. Not to worry, we can easily convert JSON into CSV using <a href="https://github.com/jehiah/json2csv">json2csv</a>. Assuming that we stored the data from the last step in <code>million.json</code>, simply invoking</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">&lt; million.json json2csv -k name,party,cash
</code></pre></div>
<p>will convert it to some nicely comma-separated values:</p>
<div class="highlight"><pre><code class="awk language-awk" data-lang="awk"><span class="nx">Barack</span> <span class="nx">Obama</span><span class="p">,</span><span class="nx">D</span><span class="p">,</span><span class="mf">29911984.0</span>
<span class="nx">John</span> <span class="nx">McCain</span><span class="p">,</span><span class="nx">R</span><span class="p">,</span><span class="mf">32812513.75</span>
<span class="nx">John</span> <span class="nx">Edwards</span><span class="p">,</span><span class="nx">D</span><span class="p">,</span><span class="mf">4428347.5</span>
</code></pre></div>
<p>Having the data in CSV format allows us to use the classic tools such as <code>cut -d,</code> and <code>awk -F,</code>. 
Others like <code>grep</code> and <code>sed</code> don&#39;t really have a notion of fields. 
Since CSV is the king of tabular file formats, according to the authors of 
<a href="http://csvkit.readthedocs.org/">csvkit</a>, they created, well, <code>csvkit</code>.</p>

<h3>3. csvkit - suite of utilities for converting to and working with CSV</h3>

<p>Rather than being one tool, <a href="http://csvkit.readthedocs.org/">csvkit</a> is a collection of tools that operate on CSV data. Most of these tools expect the CSV data to have a header, so let&#39;s add one. (Since the publication of this post, <code>json2csv</code> has been updated to print the header with the <code>-p</code> option.)</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash"><span class="nb">echo </span>name,party,cash <span class="p">|</span> cat - million.csv &gt; million-header.csv
</code></pre></div>
<p>We can, for example, sort the candidates by cash with <code>csvsort</code> and display the data using <code>csvlook</code>:</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">&lt; million-header.csv csvsort -rc cash <span class="p">|</span> csvlook

<span class="p">|</span>---------------+-------+--------------<span class="p">|</span>
<span class="p">|</span>  name         <span class="p">|</span> party <span class="p">|</span> cash         <span class="p">|</span>
<span class="p">|</span>---------------+-------+--------------<span class="p">|</span>
<span class="p">|</span>  John McCain  <span class="p">|</span> R     <span class="p">|</span> 32812513.75  <span class="p">|</span>
<span class="p">|</span>  Barack Obama <span class="p">|</span> D     <span class="p">|</span> 29911984.0   <span class="p">|</span>
<span class="p">|</span>  John Edwards <span class="p">|</span> D     <span class="p">|</span> 4428347.5    <span class="p">|</span>
<span class="p">|</span>---------------+-------+--------------<span class="p">|</span>
</code></pre></div>
<p>Looks like the MySQL console doesn&#39;t it? Speaking of databases, you can insert the CSV data into an sqlite database as follows (many other databases are supported as well):</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">csvsql --db sqlite:///myfirst.db --insert million-header.csv
sqlite3 myfirst.db
sqlite&gt; .schema million-header
</code></pre></div><div class="highlight"><pre><code class="sql language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="ss">&quot;million-header&quot;</span> <span class="p">(</span>
    <span class="n">name</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span> 
    <span class="n">party</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span> 
    <span class="n">cash</span> <span class="nb">FLOAT</span> <span class="k">NOT</span> <span class="k">NULL</span>
<span class="p">);</span>
</code></pre></div>
<p>In this case, the database columns have the correct data types because the type is inferred from the CSV data.
 Other tools within <code>csvkit</code> that might be of interest are: <code>in2csv</code>, <code>csvgrep</code>, and <code>csvjoin</code>. And with <code>csvjson</code>, the data can even be converted back to JSON. All in all, <code>csvkit</code> is worth <a href="http://csvkit.readthedocs.org/">checking out</a>. </p>

<h3>4. scrape - HTML extraction using XPath or CSS selectors</h3>

<p>JSON APIs sure are nice, but they aren&#39;t the only source of data; a lot of it is <a href="http://www.ted.com/talks/tim_berners_lee_on_the_next_web.html">unfortunately still</a> embedded in HTML. <a href="https://github.com/jeroenjanssens/data-science-toolbox">scrape</a> is a python script I put together that employs the <code>lxml</code> and <code>cssselect</code> packages to select certain HTML elements by means of an XPath query or <a href="http://net.tutsplus.com/tutorials/html-css-techniques/the-30-css-selectors-you-must-memorize/">CSS selector</a>. (I tried <a href="https://metacpan.org/module/scrape.pl">scrape.pl</a>, but I couldn&#39;t get it to work properly. Moreover, rather than processing HTML from stdin, it expects a url and then downloads the HTML itself.)
Let&#39;s extract the table from <a href="http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio">this Wikipedia article that lists the border and area ratio of each country</a>.</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">curl -s <span class="s1">&#39;http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio&#39;</span> <span class="p">|</span> scrape -b -e <span class="s1">&#39;table.wikitable &gt; tr:not(:first-child)&#39;</span> <span class="p">|</span> head
</code></pre></div><div class="highlight"><pre><code class="html language-html" data-lang="html"><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html&gt;</span>
<span class="nt">&lt;body&gt;</span>
<span class="nt">&lt;tr&gt;</span>
<span class="nt">&lt;td&gt;</span>1<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>Vatican City<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>3.2<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>0.44<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>7.2727273<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;/tr&gt;</span>
</code></pre></div>
<p>The <code>-b</code> argument lets <code>scrape</code> enclose the output with <code>&lt;html&gt;</code> and <code>&lt;body&gt;</code> tags, which is sometimes required by <code>xml2json</code> to convert correctly the HTML to JSON.</p>

<h3>5. xml2json - convert XML to JSON</h3>

<p>As its name implies, <a href="https://github.com/parmentf/xml2json">xml2json</a> takes XML (and HTML) as input and returns JSON as output. Therefore, <code>xml2json</code> is a great liaison between <code>scrape</code> and <code>jq</code>.</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">curl -s <span class="s1">&#39;http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio&#39;</span> <span class="p">|</span> scrape -be <span class="s1">&#39;table.wikitable &gt; tr:not(:first-child)&#39;</span> <span class="p">|</span> xml2json <span class="p">|</span> jq -c <span class="s1">&#39;.html.body.tr[] | {country: .td[1][], border: .td[2][], surface: .td[3][], ratio: .td[4][]}&#39;</span> <span class="p">|</span> head
</code></pre></div><div class="highlight"><pre><code class="json language-json" data-lang="json"><span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;7.2727273&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;0.44&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;3.2&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Vatican City&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;2.2000000&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;2&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;4.4&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Monaco&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;0.6393443&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;61&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;39&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;San Marino&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;0.4750000&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;160&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;76&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Liechtenstein&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;0.3000000&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;34&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;10.2&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Sint Maarten (Netherlands)&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;0.2570513&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;468&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;120.3&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Andorra&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;0.2000000&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;6&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;1.2&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Gibraltar (United Kingdom)&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;0.1888889&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;54&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;10.2&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Saint Martin (France)&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;0.1388244&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;2586&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;359&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Luxembourg&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;ratio&quot;</span><span class="p">:</span><span class="s2">&quot;0.0749196&quot;</span><span class="p">,</span><span class="nt">&quot;surface&quot;</span><span class="p">:</span><span class="s2">&quot;6220&quot;</span><span class="p">,</span><span class="nt">&quot;border&quot;</span><span class="p">:</span><span class="s2">&quot;466&quot;</span><span class="p">,</span><span class="nt">&quot;country&quot;</span><span class="p">:</span><span class="s2">&quot;Palestinian territories&quot;</span><span class="p">}</span>
</code></pre></div>
<p>Of course this JSON data could then be piped into <code>json2csv</code> and so forth.</p>

<h3>6. sample - when you&#39;re in debug mode</h3>

<p>The second tool I made is <a href="https://github.com/jeroenjanssens/data-science-toolbox/blob/master/tools/sample">sample</a>. (It&#39;s based on two scripts in <a href="https://github.com/bitly/data_hacks">bitly&#39;s data_hacks</a>, which contains some other tools worth checking out.) When you&#39;re in the process of formulating your data pipeline and you have a lot of data, then debugging your pipeline can be cumbersome. In that case, <code>sample</code> might be useful. 
The tool serves three purposes (which isn&#39;t very Unix-minded, but since it&#39;s mostly useful when you&#39;re in debug mode, that&#39;s not such a big deal). </p>

<p>The first purpose of <code>sample</code> is to get a subset of the data by outputting only a certain percentage of the input on a line-by-line basis. The second purpose is to add some delay to the output. This comes in handy when the input is a constant stream (e.g., the Twitter firehose), and the data comes in too fast to see what&#39;s going on.
The third purpose is to run only for a certain time. The following invocation illustrates all three purposes.</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">seq 10000 <span class="p">|</span> sample -r 20% -d 1000 -s 5 <span class="p">|</span> jq <span class="s1">&#39;{number: .}&#39;</span>
</code></pre></div>
<p>This way, every input line has a 20% chance of being forwarded to <code>jq</code>. Moreover, there is a 1000 millisecond delay between each line and after five seconds <code>sample</code> will stop entirely. Please note that each argument is optional. 
In order to prevent unnecessary computation, try to put <code>sample</code> as early as possible in your pipeline (the same argument holds for <code>head</code> and <code>tail</code>). Once you&#39;re done debugging you can simply take it out of the pipeline.</p>

<h3>7. Rio - making R part of the pipeline</h3>

<p>This post wouldn&#39;t be complete without some R.
It&#39;s not straightforward to make R/Rscript part of the pipeline since they don&#39;t 
work with stdin and stdout out of the box.
Therefore, as a proof of concept, I put together a bash script called <a href="https://github.com/jeroenjanssens/data-science-toolbox/blob/master/tools/Rio">Rio</a>. </p>

<p><code>Rio</code> works as follows.
First, the CSV provided to stdin is redirected to a temporary file and lets R read that into a data frame <code>df</code>.
Second, the specified commands in the <code>-e</code> option are executed.
Third, the output of the last command is redirected to stdout. 
Allow me to demonstrate three one-liners that use the Iris dataset (don&#39;t mind the url).</p>

<p>Display the five-number-summary of each field.</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">curl -s <span class="s1">&#39;https://raw.github.com/pydata/pandas/master/pandas/tests/data/iris.csv&#39;</span> &gt; iris.csv
&lt; iris.csv Rio -e <span class="s1">&#39;summary(df)&#39;</span>
</code></pre></div><div class="highlight"><pre><code class="text language-text" data-lang="text">  SepalLength      SepalWidth     PetalLength      PetalWidth   
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300  
 Mean   :5.843   Mean   :3.054   Mean   :3.759   Mean   :1.199  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
     Name          
 Length:150        
 Class :character  
 Mode  :character 
</code></pre></div>
<p>If you specify the <code>-s</code> option, the <code>sqldf</code> package will be imported.
In case tthe output is a data frame, CSV will be written to stdout. This enables you to further process that data using other tools.</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">&lt; iris.csv Rio -se <span class="s1">&#39;sqldf(&quot;select * from df where df.SepalLength &gt; 7.5&quot;)&#39;</span> <span class="p">|</span> csvlook
</code></pre></div><div class="highlight"><pre><code class="text language-text" data-lang="text">|--------------+------------+-------------+------------+-----------------|
|  SepalLength | SepalWidth | PetalLength | PetalWidth | Name            |
|--------------+------------+-------------+------------+-----------------|
|  7.6         | 3          | 6.6         | 2.1        | Iris-virginica  |
|  7.7         | 3.8        | 6.7         | 2.2        | Iris-virginica  |
|  7.7         | 2.6        | 6.9         | 2.3        | Iris-virginica  |
|  7.7         | 2.8        | 6.7         | 2          | Iris-virginica  |
|  7.9         | 3.8        | 6.4         | 2          | Iris-virginica  |
|  7.7         | 3          | 6.1         | 2.3        | Iris-virginica  |
|--------------+------------+-------------+------------+-----------------|
</code></pre></div>
<p>If you specify the <code>-g</code> option, <code>ggplot2</code> gets imported and a ggplot object called <code>g</code> with <code>df</code> as the data is initialized.
If the final output is a ggplot object, a PNG will be written to stdout.</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">&lt; iris.csv Rio -ge <span class="s1">&#39;g+geom_point(aes(x=SepalLength,y=SepalWidth,colour=Name))&#39;</span> &gt; iris.png
</code></pre></div>
<p><img src="/img/iris.png" alt="iris.csv"></p>

<p>I made this tool so that I could take advantage of the power of R on the command-line. Of course it has its limits, but at least there&#39;s no need to learn <a href="http://www.gnuplot.info">gnuplot</a> any more.</p>

<h3>Command-line tools suggested by others</h3>

<p>Below is an uncurated list of tools and repositories that others have suggested via <a href="https://twitter.com/jeroenhjanssens/">twitter</a> or <a href="https://news.ycombinator.com/item?id=6412190">Hacker News</a> (last updated on 23-09-2013 07:15 EST). Thanks everybody.</p>

<ul>
<li><a href="http://bigmler.readthedocs.org/en/latest/">BigMLer</a> by <a href="https://news.ycombinator.com/user?id=aficionado">aficionado</a></li>
<li><a href="https://code.google.com/p/crush-tools/">crush-tools</a> by <a href="https://news.ycombinator.com/user?id=mjn">mjn</a></li>
<li><a href="https://github.com/dergachev/csv2sqlite">csv2sqlite</a> by <a href="https://news.ycombinator.com/user?id=dergachev">dergachev</a></li>
<li><a href="https://github.com/dbro/csvquote">csvquote</a> by <a href="https://news.ycombinator.com/user?id=susi22">susi22</a></li>
<li><a href="https://github.com/clarkgrubb/data-tools">data-tools repository</a> by <a href="https://news.ycombinator.com/user?id=cgrubb">cgrubb</a></li>
<li><a href="https://github.com/dkogan/feedgnuplot">feedgnuplot</a> by <a href="https://news.ycombinator.com/user?id=dima55">dima55</a></li>
<li><a href="https://github.com/cgutteridge/Grinder/tree/master/bin">Grinder repository</a> by <a href="https://twitter.com/cgutteridge">@cgutteridge</a></li>
<li><a href="http://www.hdfgroup.org/HDF5/doc/RM/Tools.html">HDF5 Tools</a> by <a href="https://news.ycombinator.com/user?id=susi22">susi22</a></li>
<li><a href="http://code.google.com/p/littler/">littler</a> by <a href="https://twitter.com/eddelbuettel">@eddelbuettel</a></li>
<li><a href="http://gibrown.wordpress.com/2013/01/26/unix-bi-grams-tri-grams-and-topic-modeling/">mallet</a> by <a href="https://news.ycombinator.com/user?id=gibrown">gibrown</a></li>
<li><a href="https://github.com/benbernard/RecordStream">RecordStream</a> by <a href="https://news.ycombinator.com/user?id=revertts">revertts</a></li>
<li><a href="https://github.com/paulgb/subsample">subsample</a> by <a href="https://news.ycombinator.com/user?id=paulgb">paulgb</a></li>
<li><a href="http://search.cpan.org/%7Eken/xls2csv-1.07/script/xls2csv">xls2csv</a> by <a href="https://twitter.com/sheeshee">@sheeshee</a></li>
<li><a href="http://xmlstar.sourceforge.net/">XMLStarlet</a> by <a href="https://news.ycombinator.com/user?id=gav">gav</a></li>
</ul>

<h3>Conclusion</h3>

<p>I have shown you seven command-line tools that I use in my daily work as a data scientist.
While each tool is useful in its own way, I often find myself combining them with, or just resorting to, the classics such as <code>grep</code>, <code>sed</code>, and <code>awk</code>. Combining such small tools into a larger pipeline is what makes them really powerful.</p>

<p>I&#39;m curious to hear what you think about this list and what command-line tools you like to use.
Also, if you&#39;ve made any tools yourself, you&#39;re more than welcome to add them to this <a href="https://github.com/jeroenjanssens/data-science-toolbox">data science toolbox</a>. </p>

<p>Don&#39;t worry if you don&#39;t regard yourself as a toolmaker. The next time you&#39;re cooking up that exotic pipeline, consider to put it in a file, add a <a href="http://en.wikipedia.org/wiki/Shebang_%28Unix%29">shebang</a>, parametrize it with some <code>$1</code>s and <code>$2</code>s, and <code>chmod +x</code> it. That&#39;s all there is to it. Who knows, you might even become interested in applying the <a href="http://www.faqs.org/docs/artu/ch01s06.html">Unix philosophy</a>.</p>

<p>While the power of the command-line should not be underestimated when it comes to Obtaining, Scrubbing, and Exploring data, it can only get you so far. When you&#39;re ready to do some more serious Exploring, Modelling, and iNterpretation of your data, you&#39;re probably better off continuing your work in a statistical computing environment, such as <a href="http://www.r-project.org/">R</a> or <a href="http://ipython.org/notebook.html">IPython notebook</a>+<a href="http://pandas.pydata.org/">pandas</a>.</p>

<p>If you enjoyed this post, then you may want to <a href="https://twitter.com/jeroenhjanssens/">follow me on Twitter</a>.</p>

					</div>

			</div>
		</div>
	</body>
</html>
