<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Jeroen Janssens</title>
		<description>Dutch Data Scientist in Old New Amsterdam</description>
		<link>http://www.jeroenjanssens.com</link>
		<atom:link href="http://www.jeroenjanssens.com/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Lean, mean data science machine</title>
				<description>&lt;p&gt;Data scientists love to create interesting models and exciting data visualizations. However, before they get to that point, usually much effort goes into obtaining, scrubbing, and exploring the required data. I argue that the *nix command-line, although invented decades ago, remains a powerful environment for processing data. It provides a read-eval-print loop (REPL) that is often much more convenient for exploratory data analysis than the edit-compile-run-debug cycle associated with large programs and even scripts.&lt;/p&gt;

&lt;p&gt;Unfortunately, setting up a workable environment and installing the latest command-line tools can be quite a pain. This post describes how to alleviate that pain and how to get you started doing data science on the command-line in a matter minutes.&lt;/p&gt;

&lt;h3&gt;Data Science at the Command Line&lt;/h3&gt;

&lt;p&gt;I am currently authoring a book titled &amp;quot;Data Science at the Command Line&amp;quot;, which will be published by O&amp;#39;Reilly in summer 2014.
The main goal of the book is to teach why, how, and when the command-line could be employed for data science. The tentative outline is as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;li&gt;Getting Started&lt;/li&gt;
&lt;li&gt;Step 1: Obtaining Data&lt;/li&gt;
&lt;li&gt;Creating Reusable Command-line Tools&lt;/li&gt;
&lt;li&gt;Step 2: Scrubbing Data&lt;/li&gt;
&lt;li&gt;Managing Your Data Workflow&lt;/li&gt;
&lt;li&gt;Step 3: Exploring Data&lt;/li&gt;
&lt;li&gt;Speeding Up Data-Intensive Commands&lt;/li&gt;
&lt;li&gt;Step 4: Modeling Data&lt;/li&gt;
&lt;li&gt;Poor Man&amp;#39;s MapReduce&lt;/li&gt;
&lt;li&gt;Step 5: Interpreting Data&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Naturally, the book will be drenched with commands and source code. It is important that the text, the code, and the output of the code are consistent with each other. Manually running the code and copy-pasting the output is a cumbersome and error-prone process. 
To automate this process, I have created a script (a &lt;a href=&quot;http://www.dexy.it/&quot;&gt;dexy&lt;/a&gt; filter to be precise) that will (1) extract all the source code from the text, (2) run these in an isolated environment, and (3) paste the output back into the text. From here the O&amp;#39;Reilly toolchain takes over and converts the text to a variety of digital formats. Very smooth.&lt;/p&gt;

&lt;h3&gt;Vagrant environment for data science&lt;/h3&gt;

&lt;p&gt;The isolated environment is created and configured using &lt;a href=&quot;http://www.vagrantup.com/&quot;&gt;Vagrant&lt;/a&gt;, which is basically a wrapper around VirtualBox and other virtualization software such AWS EC2. With a few commands, a fresh virtual machine is spun up and configured according to a simple script. It was &lt;a href=&quot;http://miningthesocialweb.com/2013/11/23/confessions-of-a-prolific-moonlighter-with-a-chronic-writing-disorder&quot;&gt;Matthew Russell&amp;#39;s Ignite talk&lt;/a&gt; that inspired me to use Vagrant; he provides one for his book &lt;a href=&quot;http://miningthesocialweb.com&quot;&gt;Mining the Social Web&lt;/a&gt; that is focused more on Python.
If my Vagrant environment would be provided with Data Science at the Command Line, then the reader would be able to follow along with the commands and source code. But since my mission is to enable everybody to do data science at the command-line as soon as possible, I have decided to make it available right now.&lt;/p&gt;

&lt;p&gt;Currently, the environment includes the &lt;a href=&quot;http://jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html&quot;&gt;seven command-line tools I discussed&lt;/a&gt; a while ago and &lt;a href=&quot;http://www.gnu.org/software/parallel/&quot;&gt;GNU parallel&lt;/a&gt;, which will be discussed in Chapter 8. Just like the book itself, the environment is a work in progress. In order to be able to run &lt;a href=&quot;https://github.com/jeroenjanssens/data-science-toolbox/blob/master/tools/Rio&quot;&gt;Rio&lt;/a&gt; (one of the seven tools), I had to include the latest version of &lt;code&gt;R&lt;/code&gt;, together with the packages &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;sqldf&lt;/code&gt;, and &lt;code&gt;plyr&lt;/code&gt;. &lt;del&gt;I am aware that many of you would prefer the Python scientific stack to be included as well.&lt;/del&gt; The Python scientific stack (&lt;code&gt;ipython&lt;/code&gt;, &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, and &lt;code&gt;scikit-learn&lt;/code&gt;) is also included. However, because of disk-space and provision-time constraints, I doubt whether it is desirable (or even possible) to create an environment that includes everything. Perhaps that we can devise a solution where you select which tools, packages, and languages you would like to have installed. As mentioned, it is a work in progress and my main goal is to get you up and running on the command-line.&lt;/p&gt;

&lt;h3&gt;Installation&lt;/h3&gt;

&lt;p&gt;The environment is currently configured to run on top of &lt;a href=&quot;https://www.virtualbox.org&quot;&gt;VirtualBox&lt;/a&gt;. (I am looking into the option to deploy it on an AWS EC2 instance.)
So, first you will need to install &lt;a href=&quot;https://www.virtualbox.org&quot;&gt;VirtualBox&lt;/a&gt;. 
Second you need to install &lt;a href=&quot;http://www.vagrantup.com/&quot;&gt;Vagrant&lt;/a&gt;. 
Third, you need to download the environment by cloning the data science toolbox. (If you do not want to use &lt;code&gt;git&lt;/code&gt; you can also &lt;a href=&quot;https://github.com/jeroenjanssens/data-science-toolbox/archive/master.zip&quot;&gt;download the zip file&lt;/a&gt;.)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;git clone https://github.com/jeroenjanssens/data-science-toolbox.git
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;data-science-toolbox/box
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running &lt;code&gt;vagrant up&lt;/code&gt; in the &lt;code&gt;box&lt;/code&gt; directory will download the base box (Ubuntu 12.04 LTS 64-bit), spin up a virtual machine, and provision it. (Now would be the perfect time to think about any command-line scripts you may have lying around and donate them to the &lt;a href=&quot;http://datasciencetoolbox.org&quot;&gt;data science toolbox&lt;/a&gt;.) Once the provisioning is complete, you will be able to log into your own lean, mean data science machine: &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;vagrant ssh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Run the following command to test whether everything has been installed correctly:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -s &lt;span class=&quot;s1&quot;&gt;&amp;#39;http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; scrape -be &lt;span class=&quot;s1&quot;&gt;&amp;#39;table.wikitable &amp;gt; tr:not(:first-child)&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; xml2json &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; jq -c &lt;span class=&quot;s1&quot;&gt;&amp;#39;.html.body.tr[] | {country: .td[1][], border: .td[2][], surface: .td[3][], ratio: .td[4][]}&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; json2csv -p -k&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;country,ratio &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; Rio -se&lt;span class=&quot;s1&quot;&gt;&amp;#39;sqldf(&amp;quot;select * from df where ratio &amp;gt; 0.3 order by ratio desc&amp;quot;)&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; csvlook
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;|----------------+------------|
|  country       | ratio      |
|----------------+------------|
|  Vatican City  | 7.2727273  |
|  Monaco        | 2.2        |
|  San Marino    | 0.6393443  |
|  Liechtenstein | 0.475      |
|----------------+------------|
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The virtual machine is not entirely isolated. Files that you put in the &lt;code&gt;box&lt;/code&gt; directory will be accessible from the &lt;code&gt;/vagrant&lt;/code&gt; directory in the virtual machine. This allows you to use both the tools you already have installed and the command-line tools provided by the environment. If you want to install any of these tools on your own machine, then you can run the relevant commands from the &lt;a href=&quot;https://github.com/jeroenjanssens/data-science-toolbox/blob/master/box/bootstrap.sh&quot;&gt;provisioning script&lt;/a&gt;. &lt;/p&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;While the command-line is a very powerful environment to process data, manually installing the latest command-line tools is not straightforward. Vagrant allows you to spin up a virtual machine and to install all the tools automatically.
In this post I have shared with you the exact same Vagrant environment as that I am using for my upcoming book, in the hope that it will be useful to get you started with doing data science at the command line.
Please let me know if you have any questions, suggestions, or contributions.&lt;/p&gt;

&lt;p&gt;Best wishes,&lt;/p&gt;

&lt;p&gt;Jeroen &lt;br&gt;
&lt;a href=&quot;https://twitter.com/jeroenhjanssens/&quot;&gt;@jeroenhjanssens&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Sat, 07 Dec 2013 09:00:00 +0000</pubDate>
				<link>http://www.jeroenjanssens.com/2013/12/07/lean-mean-data-science-machine.html</link>
				<guid isPermaLink="true">http://www.jeroenjanssens.com/2013/12/07/lean-mean-data-science-machine.html</guid>
			</item>
		
			<item>
				<title>Stochastic Outlier Selection</title>
				<description>&lt;p&gt;My Ph.D., which I completed earlier this year, was about &lt;a href=&quot;https://github.com/jeroenjanssens/phd-thesis&quot;&gt;outlier selection and one-class classification&lt;/a&gt;. During this time I learned about quite a few machine learning algorithms; especially about outlier-selection algorithms and one-class classifiers, of course. With some help of &lt;a href=&quot;https://twitter.com/fhuszar&quot;&gt;Ferenc Huszár&lt;/a&gt; and &lt;a href=&quot;http://homepage.tudelft.nl/19j49/Home.html&quot;&gt;Laurens van der Maaten&lt;/a&gt;, I also came up with a new outlier-selection algorithm called &lt;a href=&quot;https://github.com/jeroenjanssens/sos&quot;&gt;Stochastic Outlier Selection&lt;/a&gt; (SOS), which I would like to briefly describe here.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sos-densities.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;If you prefer a more detailed discussion about the algorithm, the experiments, and the results, you can read either the &lt;a href=&quot;https://github.com/jeroenjanssens/sos/blob/master/doc/sos-ticc-tr-2012-001.pdf?raw=true&quot;&gt;technical report (PDF)&lt;/a&gt; or chapter 4 of &lt;a href=&quot;https://github.com/jeroenjanssens/phd-thesis&quot;&gt;my Ph.D. thesis&lt;/a&gt;. In case you can&amp;#39;t wait to see whether your own dataset contains any outliers then there&amp;#39;s a &lt;a href=&quot;https://github.com/jeroenjanssens/sos&quot;&gt;Python implementation of SOS&lt;/a&gt; which you can also use from the command-line.&lt;/p&gt;

&lt;h3&gt;Affinity-based outlier selection&lt;/h3&gt;

&lt;p&gt;SOS is an unsupervised outlier-selection algorithm that takes as input either a feature matrix or a dissimilarity matrix and outputs for each data point an outlier probability. 
Intuitively, a data point is considered to be an outlier when the other data points have insufficient affinity with it. Allow me to explain this using the following two-dimensional toy dataset.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sos-toydataset.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The right part of the figure shows that the feature matrix &lt;strong&gt;X&lt;/strong&gt; is transformed into a dissimilarity matrix &lt;strong&gt;D&lt;/strong&gt; using the Euclidean distance. (Any dissimilarity measure could have been used here.)
Using the dissimilarity matrix &lt;strong&gt;D&lt;/strong&gt;, SOS computes an affinity matrix &lt;strong&gt;A&lt;/strong&gt;, a binding probability matrix &lt;strong&gt;B&lt;/strong&gt;, and finally, the outlier probability vector &lt;strong&gt;Φ&lt;/strong&gt;, because Greek letters are cool.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sos-matrices.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The use of the concept of affinity is inspired by &lt;a href=&quot;http://homepage.tudelft.nl/19j49/t-SNE.html&quot;&gt;t-Distributed Stochastic Neighbor Embedding&lt;/a&gt; (t-SNE), which is a non-linear dimensionality reduction technique created by &lt;a href=&quot;http://homepage.tudelft.nl/19j49/Home.html&quot;&gt;Laurens van der Maaten&lt;/a&gt; and &lt;a href=&quot;http://www.cs.toronto.edu/%7Ehinton/&quot;&gt;Geoffrey Hinton&lt;/a&gt;. Both algorithms use the concept of affinity to quantify the relationship between data points. t-SNE uses it to preserve the local structure of a high-dimensional dataset and SOS uses it to select outliers.
The affinity a certain data point has with another data point decreases Gaussian-like with respect to their dissimilarity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sos-d2a.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Each data point has a variance associated with it. The variance depends on the density of the neighborhood. A higher density implies a lower variance. In fact, the variance is set such that each data point has effectively the same number of neighbors. 
This number is controlled via the only parameter of SOS, called perplexity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sos-variances.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Perplexity can be interpreted as the &lt;em&gt;k&lt;/em&gt; in &lt;em&gt;k&lt;/em&gt;-nearest neighbor algorithms. The difference is that in SOS being a neighbor is not a binary property, but a probabilistic one. The following figure illustrates the binding probabilities data point &lt;strong&gt;x1&lt;/strong&gt; (or vertex &lt;strong&gt;v1&lt;/strong&gt; because we have switched to a graph representation of the dataset) has with the other five data points.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sos-binding.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The binding probability matrix is just the affinity matrix such that the rows sum to 1. To obtain the outlier probability of data point we compute the joint probability that the other data points will &lt;em&gt;not&lt;/em&gt; bind to it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sos-closedform.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;This simple equation corresponds to the intuition behind SOS mentioned earlier: a data point is considered to be an outlier when the other data points have insufficient affinity with it. The proof behind this equation is unfortunately beyond the scope of this post. &lt;/p&gt;

&lt;p&gt;SOS has been evaluated on a variety of real-world and synthetic datasets, and compared to four other outlier-selection algorithms. The following figure shows the weighted AUC performance on 18 real-world datasets.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sos-results.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As you can see, SOS has a higher performance on most of these real-world datasets. 
However, there&amp;#39;s still the no-free-lunch theorem, which basically says that no algorithm uniformly outperforms all other algorithms on all datasets. 
So, if you&amp;#39;d like to select some outliers on your own dataset, check out SOS by all means, but keep in mind that you may obtain a higher performance with a different outlier-selection algorithm. The real questions are: which one and why?&lt;/p&gt;

&lt;p&gt;As this was a very brief description of SOS, I had to skip over many details. 
Again, in case you&amp;#39;re interested, you can read either the &lt;a href=&quot;https://github.com/jeroenjanssens/sos/blob/master/doc/sos-ticc-tr-2012-001.pdf?raw=true&quot;&gt;technical report (PDF)&lt;/a&gt; or chapter 4 of &lt;a href=&quot;https://github.com/jeroenjanssens/phd-thesis&quot;&gt;my Ph.D. thesis&lt;/a&gt;. In the next section I apply SOS to roll call voting data. &lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;detecting-anomalous-senators&quot;&gt;&lt;/a&gt;Detecting anomalous senators&lt;/h3&gt;

&lt;p&gt;Last week, I had the pleasure to talk about outlier selection and one-class classification at the &lt;a href=&quot;http://www.meetup.com/NYC-Machine-Learning/events/149093182/&quot;&gt;NYC Machine Learning meetup&lt;/a&gt;. (The video and slides will soon be put online by &lt;a href=&quot;http://g33ktalk.com/&quot;&gt;G33ktalk&lt;/a&gt;.) In order to not just show fancy graphs and boring equations I created a &lt;a href=&quot;http://bl.ocks.org/jeroenjanssens/7608890&quot;&gt;demo in D3 and CoffeeScript&lt;/a&gt;, of which you see a screenshot below. In the &lt;a href=&quot;http://bl.ocks.org/jeroenjanssens/7608890&quot;&gt;demo&lt;/a&gt;, I apply SOS on roll call voting data, which is inspired by &lt;a href=&quot;http://vikparuchuri.com/blog/how-divided-is-the-senate/&quot;&gt;this post on visualizing the senate&lt;/a&gt; by Vik Paruchuri. 
The demo illustrates how the approximated outlier probability of each senator evolves as more Stochastic Neighbor Graphs (SNG) are being sampled. (Please note that SNGs are not discussed in this post.)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://bl.ocks.org/jeroenjanssens/7608890&quot;&gt;&lt;img src=&quot;/img/sos-senators.png&quot; alt=&quot;Detecting anomalous senators&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s see how the approximated outlier probabilities compare to the outlier probabilities computed on the command-line. Recently, I started using &lt;a href=&quot;https://github.com/Factual/drake#drake&quot;&gt;drake&lt;/a&gt; to organize my data workflow. (If you care about reproducibility, then I recommend you try it out.) The following &lt;code&gt;Drakefile&lt;/code&gt; shows how to fetch the roll call voting data, extract its features and labels, and apply the &lt;a href=&quot;https://github.com/jeroenjanssens/sos/blob/master/bin/sos&quot;&gt;Python implementation of SOS&lt;/a&gt; with a perplexity of 50 to it. &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;cat Drakefile

&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;# Get dataset&lt;/span&gt;
dataset.csv &amp;lt;- &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;-timecheck&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
    curl -s https://raw.github.com/VikParuchuri/political-positions/master/113_frame.csv &amp;gt; &lt;span class=&quot;nv&quot;&gt;$OUTPUT&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;# Extract features&lt;/span&gt;
features.csv &amp;lt;- dataset.csv
    csvcut &lt;span class=&quot;nv&quot;&gt;$INPUT&lt;/span&gt; -C 1,name,party,state &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sed &lt;span class=&quot;s1&quot;&gt;&amp;#39;1d;s/NA/4/g&amp;#39;&lt;/span&gt; &amp;gt; &lt;span class=&quot;nv&quot;&gt;$OUTPUT&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;# Extract labels&lt;/span&gt;
labels.csv &amp;lt;- dataset.csv
    csvcut &lt;span class=&quot;nv&quot;&gt;$INPUT&lt;/span&gt; -c name,party,state &amp;gt; &lt;span class=&quot;nv&quot;&gt;$OUTPUT&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;# Compute outlier probabilities using SOS&lt;/span&gt;
outlier.csv &amp;lt;- features.csv
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;outlier&amp;#39;&lt;/span&gt; &amp;gt; &lt;span class=&quot;nv&quot;&gt;$OUTPUT&lt;/span&gt;
    &amp;lt; &lt;span class=&quot;nv&quot;&gt;$INPUT&lt;/span&gt; sos -p 50 &amp;gt;&amp;gt; &lt;span class=&quot;nv&quot;&gt;$OUTPUT&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;# Combine labels and outlier probabilities and sort&lt;/span&gt;
result.csv &amp;lt;- labels.csv, outlier.csv
    paste -d, &lt;span class=&quot;nv&quot;&gt;$INPUT0&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$INPUT1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; csvsort -rc outlier &amp;gt; &lt;span class=&quot;nv&quot;&gt;$OUTPUT&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;drake
head result.csv | csvlook

|-------------+-------+-------+-------------|
|  name       | party | state | outlier     |
|-------------+-------+-------+-------------|
|  Cowan      | D     | MA    | 0.91758412  |
|  Lautenberg | D     | NJ    | 0.89442425  |
|  Chiesa     | R     | NJ    | 0.8457114   |
|  Markey     | D     | MA    | 0.7813504   |
|  Kerry      | D     | MA    | 0.75302407  |
|  Wyden      | D     | OR    | 0.70110306  |
|  Murkowski  | R     | AK    | 0.68868458  |
|  Alexander  | R     | TN    | 0.626972    |
|  Vitter     | R     | LA    | 0.59739462  |
|-------------+-------+-------+-------------|
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The tools &lt;code&gt;csvcut&lt;/code&gt;, &lt;code&gt;csvsort&lt;/code&gt;, and &lt;code&gt;csvlook&lt;/code&gt; are part of &lt;a href=&quot;http://csvkit.readthedocs.org/&quot;&gt;csvkit&lt;/a&gt;. 
You may notice that the outlier probabilities shown in the screenshot do not match the exact ones computed with &lt;code&gt;sos&lt;/code&gt;. That&amp;#39;s because (1) the screenshot was taken not long after the demo started and (2) the demo was running in Chrome, which apparently has a different implementation of &lt;code&gt;Math.random&lt;/code&gt;. In Firefox, the approximated outlier probabilities will match the exact ones, eventually.&lt;/p&gt;

&lt;p&gt;If you enjoyed this post and would like to know when the video and slides will be online, then you should &lt;a href=&quot;https://twitter.com/jeroenhjanssens/&quot;&gt;follow me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Sun, 24 Nov 2013 17:06:19 +0000</pubDate>
				<link>http://www.jeroenjanssens.com/2013/11/24/stochastic-outlier-selection.html</link>
				<guid isPermaLink="true">http://www.jeroenjanssens.com/2013/11/24/stochastic-outlier-selection.html</guid>
			</item>
		
			<item>
				<title>sudo make me a visualization!</title>
				<description>&lt;p&gt;Last Monday I gave an Ignite talk at &lt;a href=&quot;http://strataconf.com/stratany2013/public/schedule/detail/32182&quot;&gt;Strata NYC&lt;/a&gt; about using command-line tools for data science.
Giving a talk where the slides auto-advance after 15 seconds is a challenging, but ultimately very rewarding experience! Even though the preview image below suggests otherwise, there&amp;#39;s no beatboxing in this video.&lt;/p&gt;

&lt;iframe style=&quot;display:block;margin: 0 auto;&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;//www.youtube.com/embed/X__Z0phLxMY&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;On a related note, I&amp;#39;m writing a book titled &amp;quot;Data Science at the Command-line&amp;quot;, which will be published by O&amp;#39;Reilly somewhere in 2014. If you&amp;#39;re interested in receiving updates regarding the book then you should &lt;a href=&quot;https://twitter.com/jeroenhjanssens/&quot;&gt;follow me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Thu, 31 Oct 2013 20:00:00 +0000</pubDate>
				<link>http://www.jeroenjanssens.com/2013/10/31/sudo-make-me-a-visualization.html</link>
				<guid isPermaLink="true">http://www.jeroenjanssens.com/2013/10/31/sudo-make-me-a-visualization.html</guid>
			</item>
		
			<item>
				<title>7 command-line tools for data science</title>
				<description>&lt;p&gt;Data science is &lt;a href=&quot;http://www.dataists.com/2010/09/a-taxonomy-of-data-science/&quot;&gt;OSEMN&lt;/a&gt; (pronounced as awesome).
That is, it involves Obtaining, Scrubbing, Exploring, Modeling, and iNterpreting data.
As a data scientist, I spend quite a bit of time on the command-line, especially when there&amp;#39;s data to be obtained, scrubbed, or explored. And I&amp;#39;m not alone in this.
Recently, &lt;a href=&quot;http://www.gregreda.com/2013/07/15/unix-commands-for-data-science/&quot;&gt;Greg Reda discussed&lt;/a&gt; how the classics (e.g., head, cut, grep, sed, and awk) can be used for data science. Prior to that, Seth Brown discussed how to perform basic &lt;a href=&quot;http://www.drbunsen.org/explorations-in-unix/&quot;&gt;exploratory data analysis in Unix&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I would like to continue this discussion by sharing seven command-line tools that I have found useful in my day-to-day work. 
The tools are:
&lt;a href=&quot;http://stedolan.github.io/jq/&quot;&gt;jq&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jehiah/json2csv&quot;&gt;json2csv&lt;/a&gt;,
&lt;a href=&quot;https://github.com/onyxfish/csvkit&quot;&gt;csvkit&lt;/a&gt;,
scrape,
&lt;a href=&quot;https://github.com/parmentf/xml2json&quot;&gt;xml2json&lt;/a&gt;,
sample, and Rio. (The home-made tools &lt;code&gt;scrape&lt;/code&gt;, &lt;code&gt;sample&lt;/code&gt;, and &lt;code&gt;Rio&lt;/code&gt; can be found in this &lt;a href=&quot;https://github.com/jeroenjanssens/data-science-toolbox&quot;&gt;data science toolbox&lt;/a&gt;.) Any suggestions, questions, comments, and even pull requests are more than welcome.
(Tools suggested by others can be found towards the bottom of the post.)
OSEMN, let&amp;#39;s get started with our first tool: &lt;code&gt;jq&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;1. jq - sed for JSON&lt;/h3&gt;

&lt;p&gt;JSON is becoming an increasingly common data format, especially as APIs are appearing everywhere. I remember cooking up the ugliest &lt;code&gt;grep&lt;/code&gt; and &lt;code&gt;sed&lt;/code&gt; incantations in order to process JSON. Thanks to &lt;code&gt;jq&lt;/code&gt;, those days are now in the past. &lt;/p&gt;

&lt;p&gt;Imagine we&amp;#39;re interested in the candidate totals of the 2008 presidential election. It so happens that the New York Times has a &lt;a href=&quot;http://developer.nytimes.com/docs/campaign_finance_api/&quot;&gt;Campaign Finance API&lt;/a&gt;. (You can &lt;a href=&quot;http://developer.nytimes.com/apps/mykeys&quot;&gt;get your own API keys&lt;/a&gt; if you want to access any of their APIs.) Let&amp;#39;s get some JSON using &lt;code&gt;curl&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -s &lt;span class=&quot;s1&quot;&gt;&amp;#39;http://api.nytimes.com/svc/elections/us/v3/finances/2008/president/totals.json?api-key=super-secret&amp;#39;&lt;/span&gt; &amp;gt; nyt.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code&gt;-s&lt;/code&gt; puts &lt;code&gt;curl&lt;/code&gt; in silent mode. In its simplest form, i.e., &lt;code&gt;jq &amp;#39;.&amp;#39;&lt;/code&gt;, the tool transforms the incomprehensible API response we got:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;{&amp;quot;status&amp;quot;:&amp;quot;OK&amp;quot;,&amp;quot;base_uri&amp;quot;:&amp;quot;http://api.nytimes.com/svc/elections/us/v3/finances/2008/&amp;quot;,&amp;quot;cycle&amp;quot;:2008,&amp;quot;copyright&amp;quot;:&amp;quot;Copyright (c) 2013 The New York Times Company. All Rights Reserved.&amp;quot;,&amp;quot;results&amp;quot;:[{&amp;quot;candidate_name&amp;quot;:&amp;quot;Obama, Barack&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Barack Obama&amp;quot;,&amp;quot;party&amp;quot;:&amp;quot;D&amp;quot;,
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;into nicely indented and colored output:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&amp;lt; nyt.json jq &lt;span class=&quot;s1&quot;&gt;&amp;#39;.&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; head
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;json language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;quot;results&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;candidate_id&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;P80003338&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;date_coverage_from&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;2007-01-01&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;date_coverage_to&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;2008-11-24&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;candidate_name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Obama, Barack&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Barack Obama&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;party&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;D&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that the output isn&amp;#39;t necessarily in the same order as the input.
Besides pretty printing, &lt;code&gt;jq&lt;/code&gt; can also select, filter, and format JSON data, as illustrated by 
the following command, which returns the name, cash, and party of each candidate that had at least $1,000,000 in cash:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&amp;lt; nyt.json jq -c &lt;span class=&quot;s1&quot;&gt;&amp;#39;.results[] | {name, party, cash: .cash_on_hand} | select(.cash | tonumber &amp;gt; 1000000)&amp;#39;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;json language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;cash&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;29911984.0&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;party&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;D&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Barack Obama&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;cash&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;32812513.75&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;party&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;R&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;John McCain&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;cash&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;4428347.5&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;party&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;D&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;John Edwards&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Please refer to the &lt;a href=&quot;http://stedolan.github.io/jq/manual/&quot;&gt;jq manual&lt;/a&gt; to read about the many other things it can do, but don&amp;#39;t expect it to solve all your data munging problems. 
Remember, the Unix philosophy favors small programs that do one thing and do it well. 
And &lt;code&gt;jq&lt;/code&gt;&amp;#39;s functionality is more than sufficient I would say! 
Now that we have the data we need, it&amp;#39;s time to move on to our second tool: &lt;code&gt;json2csv&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;2. json2csv - convert JSON to CSV&lt;/h3&gt;

&lt;p&gt;While JSON is a great format for interchanging data, it&amp;#39;s rather unsuitable for most command-line tools. Not to worry, we can easily convert JSON into CSV using &lt;a href=&quot;https://github.com/jehiah/json2csv&quot;&gt;json2csv&lt;/a&gt;. Assuming that we stored the data from the last step in &lt;code&gt;million.json&lt;/code&gt;, simply invoking&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&amp;lt; million.json json2csv -k name,party,cash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;will convert it to some nicely comma-separated values:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;awk language-awk&quot; data-lang=&quot;awk&quot;&gt;&lt;span class=&quot;nx&quot;&gt;Barack&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Obama&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;29911984.0&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;John&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;McCain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;32812513.75&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;John&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Edwards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4428347.5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Having the data in CSV format allows us to use the classic tools such as &lt;code&gt;cut -d,&lt;/code&gt; and &lt;code&gt;awk -F,&lt;/code&gt;. 
Others like &lt;code&gt;grep&lt;/code&gt; and &lt;code&gt;sed&lt;/code&gt; don&amp;#39;t really have a notion of fields. 
Since CSV is the king of tabular file formats, according to the authors of 
&lt;a href=&quot;http://csvkit.readthedocs.org/&quot;&gt;csvkit&lt;/a&gt;, they created, well, &lt;code&gt;csvkit&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;3. csvkit - suite of utilities for converting to and working with CSV&lt;/h3&gt;

&lt;p&gt;Rather than being one tool, &lt;a href=&quot;http://csvkit.readthedocs.org/&quot;&gt;csvkit&lt;/a&gt; is a collection of tools that operate on CSV data. Most of these tools expect the CSV data to have a header, so let&amp;#39;s add one. (Since the publication of this post, &lt;code&gt;json2csv&lt;/code&gt; has been updated to print the header with the &lt;code&gt;-p&lt;/code&gt; option.)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;name,party,cash &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; cat - million.csv &amp;gt; million-header.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can, for example, sort the candidates by cash with &lt;code&gt;csvsort&lt;/code&gt; and display the data using &lt;code&gt;csvlook&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&amp;lt; million-header.csv csvsort -rc cash &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; csvlook

&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;---------------+-------+--------------&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;  name         &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; party &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; cash         &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;---------------+-------+--------------&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;  John McCain  &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; R     &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; 32812513.75  &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;  Barack Obama &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; D     &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; 29911984.0   &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;  John Edwards &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; D     &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; 4428347.5    &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;---------------+-------+--------------&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Looks like the MySQL console doesn&amp;#39;t it? Speaking of databases, you can insert the CSV data into an sqlite database as follows (many other databases are supported as well):&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;csvsql --db sqlite:///myfirst.db --insert million-header.csv
sqlite3 myfirst.db
sqlite&amp;gt; .schema million-header
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;sql language-sql&quot; data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;&amp;quot;million-header&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;party&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;cash&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, the database columns have the correct data types because the type is inferred from the CSV data.
 Other tools within &lt;code&gt;csvkit&lt;/code&gt; that might be of interest are: &lt;code&gt;in2csv&lt;/code&gt;, &lt;code&gt;csvgrep&lt;/code&gt;, and &lt;code&gt;csvjoin&lt;/code&gt;. And with &lt;code&gt;csvjson&lt;/code&gt;, the data can even be converted back to JSON. All in all, &lt;code&gt;csvkit&lt;/code&gt; is worth &lt;a href=&quot;http://csvkit.readthedocs.org/&quot;&gt;checking out&lt;/a&gt;. &lt;/p&gt;

&lt;h3&gt;4. scrape - HTML extraction using XPath or CSS selectors&lt;/h3&gt;

&lt;p&gt;JSON APIs sure are nice, but they aren&amp;#39;t the only source of data; a lot of it is &lt;a href=&quot;http://www.ted.com/talks/tim_berners_lee_on_the_next_web.html&quot;&gt;unfortunately still&lt;/a&gt; embedded in HTML. &lt;a href=&quot;https://github.com/jeroenjanssens/data-science-toolbox&quot;&gt;scrape&lt;/a&gt; is a python script I put together that employs the &lt;code&gt;lxml&lt;/code&gt; and &lt;code&gt;cssselect&lt;/code&gt; packages to select certain HTML elements by means of an XPath query or &lt;a href=&quot;http://net.tutsplus.com/tutorials/html-css-techniques/the-30-css-selectors-you-must-memorize/&quot;&gt;CSS selector&lt;/a&gt;. (I tried &lt;a href=&quot;https://metacpan.org/module/scrape.pl&quot;&gt;scrape.pl&lt;/a&gt;, but I couldn&amp;#39;t get it to work properly. Moreover, rather than processing HTML from stdin, it expects a url and then downloads the HTML itself.)
Let&amp;#39;s extract the table from &lt;a href=&quot;http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio&quot;&gt;this Wikipedia article that lists the border and area ratio of each country&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -s &lt;span class=&quot;s1&quot;&gt;&amp;#39;http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; scrape -b -e &lt;span class=&quot;s1&quot;&gt;&amp;#39;table.wikitable &amp;gt; tr:not(:first-child)&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; head
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;html language-html&quot; data-lang=&quot;html&quot;&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;tr&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;td&amp;gt;&lt;/span&gt;1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/td&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;td&amp;gt;&lt;/span&gt;Vatican City&lt;span class=&quot;nt&quot;&gt;&amp;lt;/td&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;td&amp;gt;&lt;/span&gt;3.2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/td&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;td&amp;gt;&lt;/span&gt;0.44&lt;span class=&quot;nt&quot;&gt;&amp;lt;/td&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;td&amp;gt;&lt;/span&gt;7.2727273&lt;span class=&quot;nt&quot;&gt;&amp;lt;/td&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/tr&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;-b&lt;/code&gt; argument lets &lt;code&gt;scrape&lt;/code&gt; enclose the output with &lt;code&gt;&amp;lt;html&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt; tags, which is sometimes required by &lt;code&gt;xml2json&lt;/code&gt; to convert correctly the HTML to JSON.&lt;/p&gt;

&lt;h3&gt;5. xml2json - convert XML to JSON&lt;/h3&gt;

&lt;p&gt;As its name implies, &lt;a href=&quot;https://github.com/parmentf/xml2json&quot;&gt;xml2json&lt;/a&gt; takes XML (and HTML) as input and returns JSON as output. Therefore, &lt;code&gt;xml2json&lt;/code&gt; is a great liaison between &lt;code&gt;scrape&lt;/code&gt; and &lt;code&gt;jq&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -s &lt;span class=&quot;s1&quot;&gt;&amp;#39;http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; scrape -be &lt;span class=&quot;s1&quot;&gt;&amp;#39;table.wikitable &amp;gt; tr:not(:first-child)&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; xml2json &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; jq -c &lt;span class=&quot;s1&quot;&gt;&amp;#39;.html.body.tr[] | {country: .td[1][], border: .td[2][], surface: .td[3][], ratio: .td[4][]}&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; head
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;json language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;7.2727273&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.44&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;3.2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Vatican City&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;2.2000000&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;4.4&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Monaco&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.6393443&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;61&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;39&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;San Marino&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.4750000&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;160&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;76&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Liechtenstein&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.3000000&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;34&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;10.2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Sint Maarten (Netherlands)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.2570513&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;468&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;120.3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Andorra&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.2000000&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;6&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;1.2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Gibraltar (United Kingdom)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.1888889&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;54&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;10.2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Saint Martin (France)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.1388244&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;2586&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;359&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Luxembourg&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;ratio&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;0.0749196&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;surface&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;6220&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;border&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;466&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;quot;country&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Palestinian territories&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Of course this JSON data could then be piped into &lt;code&gt;json2csv&lt;/code&gt; and so forth.&lt;/p&gt;

&lt;h3&gt;6. sample - when you&amp;#39;re in debug mode&lt;/h3&gt;

&lt;p&gt;The second tool I made is &lt;a href=&quot;https://github.com/jeroenjanssens/data-science-toolbox/blob/master/sample&quot;&gt;sample&lt;/a&gt;. (It&amp;#39;s based on two scripts in &lt;a href=&quot;https://github.com/bitly/data_hacks&quot;&gt;bitly&amp;#39;s data_hacks&lt;/a&gt;, which contains some other tools worth checking out.) When you&amp;#39;re in the process of formulating your data pipeline and you have a lot of data, then debugging your pipeline can be cumbersome. In that case, &lt;code&gt;sample&lt;/code&gt; might be useful. 
The tool serves three purposes (which isn&amp;#39;t very Unix-minded, but since it&amp;#39;s mostly useful when you&amp;#39;re in debug mode, that&amp;#39;s not such a big deal). &lt;/p&gt;

&lt;p&gt;The first purpose of &lt;code&gt;sample&lt;/code&gt; is to get a subset of the data by outputting only a certain percentage of the input on a line-by-line basis. The second purpose is to add some delay to the output. This comes in handy when the input is a constant stream (e.g., the Twitter firehose), and the data comes in too fast to see what&amp;#39;s going on.
The third purpose is to run only for a certain time. The following invocation illustrates all three purposes.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;seq 10000 &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sample -r 20% -d 1000 -s 5 &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; jq &lt;span class=&quot;s1&quot;&gt;&amp;#39;{number: .}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This way, every input line has a 20% chance of being forwarded to &lt;code&gt;jq&lt;/code&gt;. Moreover, there is a 1000 millisecond delay between each line and after five seconds &lt;code&gt;sample&lt;/code&gt; will stop entirely. Please note that each argument is optional. 
In order to prevent unnecessary computation, try to put &lt;code&gt;sample&lt;/code&gt; as early as possible in your pipeline (the same argument holds for &lt;code&gt;head&lt;/code&gt; and &lt;code&gt;tail&lt;/code&gt;). Once you&amp;#39;re done debugging you can simply take it out of the pipeline.&lt;/p&gt;

&lt;h3&gt;7. Rio - making R part of the pipeline&lt;/h3&gt;

&lt;p&gt;This post wouldn&amp;#39;t be complete without some R.
It&amp;#39;s not straightforward to make R/Rscript part of the pipeline since they don&amp;#39;t 
work with stdin and stdout out of the box.
Therefore, as a proof of concept, I put together a bash script called &lt;a href=&quot;https://github.com/jeroenjanssens/data-science-toolbox/blob/master/Rio&quot;&gt;Rio&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;&lt;code&gt;Rio&lt;/code&gt; works as follows.
First, the CSV provided to stdin is redirected to a temporary file and lets R read that into a data frame &lt;code&gt;df&lt;/code&gt;.
Second, the specified commands in the &lt;code&gt;-e&lt;/code&gt; option are executed.
Third, the output of the last command is redirected to stdout. 
Allow me to demonstrate three one-liners that use the Iris dataset (don&amp;#39;t mind the url).&lt;/p&gt;

&lt;p&gt;Display the five-number-summary of each field.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -s &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://raw.github.com/pydata/pandas/master/pandas/tests/data/iris.csv&amp;#39;&lt;/span&gt; &amp;gt; iris.csv
&amp;lt; iris.csv Rio -e &lt;span class=&quot;s1&quot;&gt;&amp;#39;summary(df)&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;  SepalLength      SepalWidth     PetalLength      PetalWidth   
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300  
 Mean   :5.843   Mean   :3.054   Mean   :3.759   Mean   :1.199  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
     Name          
 Length:150        
 Class :character  
 Mode  :character 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you specify the &lt;code&gt;-s&lt;/code&gt; option, the &lt;code&gt;sqldf&lt;/code&gt; package will be imported.
In case tthe output is a data frame, CSV will be written to stdout. This enables you to further process that data using other tools.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&amp;lt; iris.csv Rio -se &lt;span class=&quot;s1&quot;&gt;&amp;#39;sqldf(&amp;quot;select * from df where df.SepalLength &amp;gt; 7.5&amp;quot;)&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; csvlook
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;|--------------+------------+-------------+------------+-----------------|
|  SepalLength | SepalWidth | PetalLength | PetalWidth | Name            |
|--------------+------------+-------------+------------+-----------------|
|  7.6         | 3          | 6.6         | 2.1        | Iris-virginica  |
|  7.7         | 3.8        | 6.7         | 2.2        | Iris-virginica  |
|  7.7         | 2.6        | 6.9         | 2.3        | Iris-virginica  |
|  7.7         | 2.8        | 6.7         | 2          | Iris-virginica  |
|  7.9         | 3.8        | 6.4         | 2          | Iris-virginica  |
|  7.7         | 3          | 6.1         | 2.3        | Iris-virginica  |
|--------------+------------+-------------+------------+-----------------|
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you specify the &lt;code&gt;-g&lt;/code&gt; option, &lt;code&gt;ggplot2&lt;/code&gt; gets imported and a ggplot object called &lt;code&gt;g&lt;/code&gt; with &lt;code&gt;df&lt;/code&gt; as the data is initialized.
If the final output is a ggplot object, a PNG will be written to stdout.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&amp;lt; iris.csv Rio -ge &lt;span class=&quot;s1&quot;&gt;&amp;#39;g+geom_point(aes(x=SepalLength,y=SepalWidth,colour=Name))&amp;#39;&lt;/span&gt; &amp;gt; iris.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/iris.png&quot; alt=&quot;iris.csv&quot;&gt;&lt;/p&gt;

&lt;p&gt;I made this tool so that I could take advantage of the power of R on the command-line. Of course it has its limits, but at least there&amp;#39;s no need to learn &lt;a href=&quot;http://www.gnuplot.info&quot;&gt;gnuplot&lt;/a&gt; any more.&lt;/p&gt;

&lt;h3&gt;Command-line tools suggested by others&lt;/h3&gt;

&lt;p&gt;Below is an uncurated list of tools and repositories that others have suggested via &lt;a href=&quot;https://twitter.com/jeroenhjanssens/&quot;&gt;twitter&lt;/a&gt; or &lt;a href=&quot;https://news.ycombinator.com/item?id=6412190&quot;&gt;Hacker News&lt;/a&gt; (last updated on 23-09-2013 07:15 EST). Thanks everybody.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://bigmler.readthedocs.org/en/latest/&quot;&gt;BigMLer&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=aficionado&quot;&gt;aficionado&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://code.google.com/p/crush-tools/&quot;&gt;crush-tools&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=mjn&quot;&gt;mjn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/dergachev/csv2sqlite&quot;&gt;csv2sqlite&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=dergachev&quot;&gt;dergachev&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/dbro/csvquote&quot;&gt;csvquote&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=susi22&quot;&gt;susi22&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/clarkgrubb/data-tools&quot;&gt;data-tools repository&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=cgrubb&quot;&gt;cgrubb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/dkogan/feedgnuplot&quot;&gt;feedgnuplot&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=dima55&quot;&gt;dima55&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/cgutteridge/Grinder/tree/master/bin&quot;&gt;Grinder repository&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/cgutteridge&quot;&gt;@cgutteridge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.hdfgroup.org/HDF5/doc/RM/Tools.html&quot;&gt;HDF5 Tools&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=susi22&quot;&gt;susi22&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://code.google.com/p/littler/&quot;&gt;littler&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/eddelbuettel&quot;&gt;@eddelbuettel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://gibrown.wordpress.com/2013/01/26/unix-bi-grams-tri-grams-and-topic-modeling/&quot;&gt;mallet&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=gibrown&quot;&gt;gibrown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/benbernard/RecordStream&quot;&gt;RecordStream&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=revertts&quot;&gt;revertts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/paulgb/subsample&quot;&gt;subsample&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=paulgb&quot;&gt;paulgb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://search.cpan.org/%7Eken/xls2csv-1.07/script/xls2csv&quot;&gt;xls2csv&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/sheeshee&quot;&gt;@sheeshee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://xmlstar.sourceforge.net/&quot;&gt;XMLStarlet&lt;/a&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=gav&quot;&gt;gav&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;I have shown you seven command-line tools that I use in my daily work as a data scientist.
While each tool is useful in its own way, I often find myself combining them with, or just resorting to, the classics such as &lt;code&gt;grep&lt;/code&gt;, &lt;code&gt;sed&lt;/code&gt;, and &lt;code&gt;awk&lt;/code&gt;. Combining such small tools into a larger pipeline is what makes them really powerful.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m curious to hear what you think about this list and what command-line tools you like to use.
Also, if you&amp;#39;ve made any tools yourself, you&amp;#39;re more than welcome to add them to this &lt;a href=&quot;https://github.com/jeroenjanssens/data-science-toolbox&quot;&gt;data science toolbox&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Don&amp;#39;t worry if you don&amp;#39;t regard yourself as a toolmaker. The next time you&amp;#39;re cooking up that exotic pipeline, consider to put it in a file, add a &lt;a href=&quot;http://en.wikipedia.org/wiki/Shebang_%28Unix%29&quot;&gt;shebang&lt;/a&gt;, parametrize it with some &lt;code&gt;$1&lt;/code&gt;s and &lt;code&gt;$2&lt;/code&gt;s, and &lt;code&gt;chmod +x&lt;/code&gt; it. That&amp;#39;s all there is to it. Who knows, you might even become interested in applying the &lt;a href=&quot;http://www.faqs.org/docs/artu/ch01s06.html&quot;&gt;Unix philosophy&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While the power of the command-line should not be underestimated when it comes to Obtaining, Scrubbing, and Exploring data, it can only get you so far. When you&amp;#39;re ready to do some more serious Exploring, Modelling, and iNterpretation of your data, you&amp;#39;re probably better off continuing your work in a statistical computing environment, such as &lt;a href=&quot;http://www.r-project.org/&quot;&gt;R&lt;/a&gt; or &lt;a href=&quot;http://ipython.org/notebook.html&quot;&gt;IPython notebook&lt;/a&gt;+&lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you enjoyed this post, then you may want to &lt;a href=&quot;https://twitter.com/jeroenhjanssens/&quot;&gt;follow me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Thu, 19 Sep 2013 12:00:00 +0000</pubDate>
				<link>http://www.jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html</link>
				<guid isPermaLink="true">http://www.jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html</guid>
			</item>
		
			<item>
				<title>Extracting text from HTML with Reporter</title>
				<description>&lt;p&gt;&lt;em&gt;Note: This post originally appeared on November 11, 2012 on &lt;a href=&quot;http://visualrevenue.com/blog&quot;&gt;Visual Revenue&amp;#39;s blog&lt;/a&gt;. The text from the &lt;a href=&quot;https://github.com/visualrevenue/reporter&quot;&gt;Github repository&lt;/a&gt; has been appended for completeness.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;At Visual Revenue, we use many great open source software packages. Our favorites include: &lt;a href=&quot;http://www.ubuntu.com/&quot;&gt;ubuntu&lt;/a&gt;, &lt;a href=&quot;http://www.vim.org/&quot;&gt;vim&lt;/a&gt;, &lt;a href=&quot;http://www.gnu.org/software/emacs/&quot;&gt;emacs&lt;/a&gt;, &lt;a href=&quot;http://git-scm.com/&quot;&gt;git&lt;/a&gt;, &lt;a href=&quot;http://www.mongodb.org/&quot;&gt;mongodb&lt;/a&gt;, &lt;a href=&quot;http://seleniumhq.org/&quot;&gt;selenium&lt;/a&gt;, &lt;a href=&quot;http://redis.io/&quot;&gt;redis&lt;/a&gt;, &lt;a href=&quot;http://ipython.org/&quot;&gt;ipython&lt;/a&gt;, &lt;a href=&quot;http://scikit-learn.org/stable/&quot;&gt;scikit-learn&lt;/a&gt;, &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt;, &lt;a href=&quot;http://www.r-project.org/&quot;&gt;R&lt;/a&gt;, and &lt;a href=&quot;http://d3js.org/&quot;&gt;D3&lt;/a&gt;. This open source tech helps us to develop a state-of-the-art recommendation platform for news editors. I&amp;#39;m happy to announce that we can now give something back to the open source community: Reporter.&lt;/p&gt;

&lt;p&gt;Reporter is being developed at &lt;a href=&quot;http://www.visualrevenue.com&quot;&gt;Visual Revenue, Inc.&lt;/a&gt; where it is used to extract the main text from news articles. The name Reporter and internal terms are inspired by the news domain.&lt;/p&gt;

&lt;p&gt;Reporter is a flexible tool that extracts text from HTML. At Visual Revenue, we actively use it to extract the main text from news articles. It is written in Python, which allows you to embed it in your own Python applications. You can also use Reporter from the command line.&lt;/p&gt;

&lt;p&gt;In short, Reporter:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;  Extracts the main text from HTML.&lt;/li&gt;
&lt;li&gt;  Uses a white-box scoring algorithm to determine the main text container.&lt;/li&gt;
&lt;li&gt;  Can easily be extended.&lt;/li&gt;
&lt;li&gt;  Supports Unicode without pain.&lt;/li&gt;
&lt;li&gt;  Has awesome debugging facilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below, I&amp;#39;ll explain how the scoring algorithm works.&lt;/p&gt;

&lt;h3&gt;Download&lt;/h3&gt;

&lt;p&gt;You can read more about Reporter on Github:
&lt;a href=&quot;https://github.com/visualrevenue/reporter&quot;&gt;https://github.com/visualrevenue/reporter&lt;/a&gt;. It&amp;#39;s also available as a PyPi package:
&lt;a href=&quot;http://pypi.python.org/pypi/reporter/0.1.2&quot;&gt;http://pypi.python.org/pypi/reporter/0.1.2&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Usage&lt;/h3&gt;

&lt;p&gt;Reporter can be invoked from the command line:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;reporter.py --url URL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The HTML from URL will be parsed by &lt;a href=&quot;http://www.crummy.com/software/BeautifulSoup/bs4/doc/&quot;&gt;Beautiful Soup&lt;/a&gt; and the main
text will be printed on stdout. If the &lt;strong&gt;--debug&lt;/strong&gt; flag is added, the text and HTML will be saved to file. The HTML will be styled as follows. Each tag will get a background color based on its score, ranging from red (low score) to green (high score). Moreover, the tag that is selected as news container (see below) will have a blue dashed line.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/scoring.png&quot; alt=&quot;Scoring&quot;&gt;&lt;/p&gt;

&lt;p&gt;If the &lt;strong&gt;--test&lt;/strong&gt; flag is given, all files in ./test/input will be processed, and the text and HTML will be saved, as in &lt;strong&gt;--debug&lt;/strong&gt;. This is useful for processing many local files, so that these only have to downloaded once. &lt;/p&gt;

&lt;p&gt;Please see &lt;strong&gt;./reporter.py --help&lt;/strong&gt; for more options.&lt;/p&gt;

&lt;p&gt;Reporter can also be used from Python:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;my_reporter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reporter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_reporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;http://example.com&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_reporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;report_news&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Scoring algorithm&lt;/h3&gt;

&lt;p&gt;To extract the main text from an HTML document, Reporter gives each HTML tag (e.g., DIV, H1, and P) a score. The text contained in the tag with the highest score is returned as the main text of the news article.&lt;/p&gt;

&lt;p&gt;The main part of the scoring algorithm is based on traversing the parsed HTML and works as follows. Reporter traverses the HTML in reverse order, i.e., it starts at the leaves of the DOM tree. Each tag is scored either as a paragraph or as a container. A tag is considered to be a paragraph (in the abstract sense, not in the P sense) when it contains more than 10 characters*, otherwise it is considered to be a container. The exact scoring of a tag is defined in the &lt;strong&gt;Autocue&lt;/strong&gt;. An Autocue is a list of scoring rules that get triggered at various stages. For example, when a tag is to be scored as a paragraph, one rule may count the number of words and return 2 points per word. Once a tag (and its siblings) are scored, its parent is scored. If the parent is also considered to be a paragraph, which happens, for
instance, with the P tag in: &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;html language-html&quot; data-lang=&quot;html&quot;&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;DIV&amp;gt;&amp;lt;P&amp;gt;&lt;/span&gt;Hello World, this is the &lt;span class=&quot;nt&quot;&gt;&amp;lt;B&amp;gt;&lt;/span&gt;Reporter package&lt;span class=&quot;nt&quot;&gt;&amp;lt;/B&amp;gt;&amp;lt;/P&amp;gt;&amp;lt;/DIV&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;the scores of the B tag are discarded and the complete text is re-scored. The DIV tag is scored as a container because (in this case) it contains no text by itself. In fact, there is
an important scoring rule which penalises containers. If such a rule would not be included, the HTML tag would always receive the highest score, which would not be very effective. &lt;/p&gt;

&lt;p&gt;&lt;em&gt;*) Currently, this is the only heuristic that is hard-coded. In
&lt;a href=&quot;https://github.com/gfxmonk/python-readability&quot;&gt;Readability&lt;/a&gt;, which served as the inspiration for Reporter, all scoring is hard-coded.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As mentioned, a scoring rule is triggered at a certain stage as the Reporter is processing the Autocue. Below, we list and explain the seven triggers with Python code. (The complete default Autocue is in &lt;strong&gt;autocues.py&lt;/strong&gt;, which is easily extensible with additional rules.)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;HTML&lt;/strong&gt;, operates on the raw HTML. For example: split a paragraph with two consecutive line breaks into two paragraphs&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;default_autocue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RegExReplacer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;lt;br */? *&amp;gt;[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;n]\*&amp;lt;br */? *&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HTML&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PRE_TRAVERSAL&lt;/strong&gt;, scores or prunes (deletes tags) before the DOM is traversed. This is useful for getting rid of specific tags such as footers, or give positive scores to certain tags For example, delete all comments (specific to a certain news property):&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;\&lt;span class=&quot;n&quot;&gt;_autocue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CSSSelector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;div#comments&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pruner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PRE&lt;/span&gt;\&lt;span class=&quot;n&quot;&gt;_TRAVERSAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, the HTML will be traversed as explained above.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;EVAL_PARAGRAPH&lt;/strong&gt;, scores a tag as a paragraph. For example, by counting words.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;\&lt;span class=&quot;n&quot;&gt;_autocue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Scorer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RegExMatcher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;(\w)+([&amp;#39;`]\w)?&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;word&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reset_children&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EVAL_PARAGRAPH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;EVAL_CONTAINER&lt;/strong&gt;, scores a tag as a container. For example, combining the scores of the children tags with a 70 points penalty, giving a minimal score of 0.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;default_autocue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ScoreAggregator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_score&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EVAL_CONTAINER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This concludes the traversing of the HTML.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;POST_TRAVERSAL&lt;/strong&gt;, scores or prunes tags after Reporter has traversed the HTML. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The tag with the highest score is selected as news container.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;NEWS_CONTAINER&lt;/strong&gt; is like POST_TRAVERSAL but only applies to the tag that is selected as news container.&lt;/p&gt;

&lt;p&gt;Example: penalize DIVs inside the news container:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;default_autocue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CSSSelector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;div&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Scorer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FixedValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NEWS_CONTAINER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Example: Get rid of any tags that have a score below -50:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;default_autocue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ScoreSelector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;upper&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pruner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NEWS_CONTAINER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;NEWS_TEXT&lt;/strong&gt;, operates on the text inside the news container. For example, put all text on one line:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;default_autocue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RegExReplacer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;\s+&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NEWS_TEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, we can return the final text as the main text of the HTML!&lt;/p&gt;

&lt;p&gt;If you like what I had to say then you may want to &lt;a href=&quot;https://twitter.com/jeroenhjanssens&quot;&gt;follow me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Sat, 31 Aug 2013 12:00:00 +0000</pubDate>
				<link>http://www.jeroenjanssens.com/2013/08/31/extracting-text-from-html-with-reporter.html</link>
				<guid isPermaLink="true">http://www.jeroenjanssens.com/2013/08/31/extracting-text-from-html-with-reporter.html</guid>
			</item>
		
			<item>
				<title>Bayesian headline testing at Visual Revenue</title>
				<description>&lt;p&gt;&lt;em&gt;Note: This post originally appeared on February 4, 2013 on &lt;a href=&quot;http://visualrevenue.com/blog&quot;&gt;Visual Revenue&amp;#39;s blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The Visual Revenue platform provides a number of great tools that support editors to optimize their front page. &lt;a href=&quot;http://visualrevenue.com/instant-headline-testing&quot;&gt;Instant Headline Testing&lt;/a&gt; is one of those tools. The quality of a story headline greatly influences its click-through-rate (CTR). Front page editors therefore spend a lot of thought coming up with the right wording to engage their readers. But on digital media, headlines do not have to be set in stone. Instant Headline Testing gives the editor the opportunity to &lt;a href=&quot;http://visualrevenue.com/blog/2012/08/usa-today-sports-boosted-their-olympics-coverage-by-57-with-headline-testing.html&quot;&gt;improve the quality of a headline&lt;/a&gt; after it has made the front page. Let me give you an example.&lt;/p&gt;

&lt;h3&gt;A sporty example&lt;/h3&gt;

&lt;p&gt;With Super Bowl XLVII (and its power outage) still fresh in our minds, one of our clients, &lt;a href=&quot;http://www.usatoday.com/sports/&quot;&gt;USA Today Sports&lt;/a&gt;, used our platform to conduct the following headline test:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Headline A: &amp;quot;What Harbaugh regrets about Super Bowl&amp;quot; (3.06% CTR)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Headline B: &amp;quot;John Harbaugh explains Super Bowl tirade&amp;quot; (4.93% CTR)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Headline A (the original headline) got 3.06% CTR and headline B got 4.93% CTR, which are both strong CTRs. After only seven minutes of testing the two headlines, headline B had been declared winner with 99.93% certainty (explained later). Subsequently, the winning headline was served to 100% of the audience for over one hour. Finally, the editor even made the change permanent in their CMS. Note that by changing a few words only, a 61% lift had been achieved, which eventually resulted in tens of thousands more views for &lt;a href=&quot;http://www.usatoday.com/story/sports/nfl/2013/02/04/ravens-john-harbaugh-super-bowl-jim-harbaugh-49ers/1890387/&quot;&gt;that article&lt;/a&gt;!&lt;/p&gt;

&lt;h3&gt;Four challenges for instant headline testing&lt;/h3&gt;

&lt;p&gt;Instant Headline Testing is essentially &lt;a href=&quot;http://www.alistapart.com/articles/a-primer-on-a-b-testing/&quot;&gt;A/B testing&lt;/a&gt; for story headlines. However, there are four challenges when it comes to Instant Headline Testing that we need to take into account.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Headlines may be on the front page for only a couple of hours, so a headline test cannot take too long.&lt;/li&gt;
&lt;li&gt;The number of readers varies greatly per front page.&lt;/li&gt;
&lt;li&gt;The CTR of a headline depends on where it is positioned on the front page. For example, a headline positioned at the hero spot has a much higher CTR than one positioned at bottom.&lt;/li&gt;
&lt;li&gt;Front pages are dynamic, so headlines can change position.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;Frequentist approach to instant headline testing&lt;/h3&gt;

&lt;p&gt;Our improved implementation overcomes these four challenges by using a Bayesian approach. Before I explain that, I’ll first discuss the frequentist approach to Instant Headline Testing.&lt;/p&gt;

&lt;p&gt;To conclude which headline is better than the other, we cannot just look at the highest CTR. We need to apply statistics in order make sure that the difference in CTR did not happen by chance. It may be the case that we cannot declare a headline as winner at all.&lt;/p&gt;

&lt;p&gt;We apply statistics to the data that we have collected during the headline test. This data includes front page impressions (i.e., views) and clicks. The more data the better, right? Well, not quite. It’s important to realize is that the longer a headline test is running, the longer we are serving one headline of possibly lesser quality to 50% of the readers. This means that the corresponding article may lose out on value. In decision theory, the difference between the actual and potential article impressions is known as &lt;a href=&quot;http://en.wikipedia.org/wiki/Regret_(decision_theory)&quot;&gt;regret&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, on the one hand, we want to collect as much data as possible in order to make a reliable conclusion, while on the other hand, we want to maximize article impressions, i.e., minimize regret. This raises two questions: (1) When can we stop a headline test? and (2) How do we know that one headline is better than the other?&lt;/p&gt;

&lt;p&gt;Within statistics, the frequentist approach and the Bayesian approach are two well-known approaches when it comes to A/B testing. The frequentist approach provides a &lt;a href=&quot;http://visualwebsiteoptimizer.com/ab-split-significance-calculator/&quot;&gt;statistical test&lt;/a&gt; whether the CTRs of the two headlines are &lt;a href=&quot;http://en.wikipedia.org/wiki/Statistical_significance&quot;&gt;significantly different&lt;/a&gt;. That would answer our second question.&lt;/p&gt;

&lt;p&gt;The frequentist approach doesn’t provide an easy answer to the first question because the statistical test assumes that the number of views are fixed before we start a headline test. Furthermore, we cannot run a headline test until we see a significant difference between CTRs as this would falsely increase the probability of obtaining a significant result, as &lt;a href=&quot;http://www.evanmiller.org/how-not-to-run-an-ab-test.html&quot;&gt;Evan Mill explains on his blog&lt;/a&gt;. We would have to estimate how many views we would need in order to obtain a significant difference.&lt;/p&gt;

&lt;p&gt;And this is where the four challenges come into play. Due to challenge 1, the headline test cannot take too long, say 20 minutes at most, which limits the number of views we can get. Because of challenge 2, the views per minute may be anything between 10 and 10,000, and we do need to have a tool that’s usable by all our front page editors. Challenge 3 determines the CTRs of the headlines as well. When the CTRs are closer together, we need more views in order to obtain a statistically significant difference. Including these three challenges when estimating the desired number of views is not straightforward. On top of that, when a headline changes position during a test (which is the fourth challenge), our estimate becomes completely invalid!&lt;/p&gt;

&lt;p&gt;Let’s have a look at a Bayesian approach to Instant Headline Testing, which is one that I find much more straightforward and elegant.&lt;/p&gt;

&lt;h3&gt;Bayesian approach to instant headline testing&lt;/h3&gt;

&lt;p&gt;Whereas the frequentist approach assumes that the “true” CTRs remain the same, all that the Bayesian approach cares about is the data we have actually observed. So, we don’t need to worry about estimating the required number of views beforehand. Moreover, the Bayesian approach doesn’t mind that headlines change position while testing, so that overcomes challenge 4.&lt;/p&gt;

&lt;p&gt;Below I’ll first explain how the Bayesian approach determines when to stop a headline test (which was our first question). The second question, determining whether one headline is better than the other is discussed in the next section.&lt;/p&gt;

&lt;p&gt;During the headline test we keep track of number of views and number of clicks on headline A and B. Important here is the absolute difference between the number of clicks both headlines. When the absolute difference crosses the so-called Anscombe boundary, we stop the headline test.&lt;/p&gt;

&lt;p&gt;The Anscombe boundary is defined in terms of (1) the number of views so far, (denoted by &lt;img src=&quot;/img/eq_n.gif&quot; alt=&quot;&quot;&gt;) and (2) the number of views we will be serving the winning headline (denoted by &lt;img src=&quot;/img/eq_k.gif&quot; alt=&quot;&quot;&gt;). Stated more formally, we stop when the following inequality is true:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/eq_anscombe.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;where &lt;img src=&quot;/img/eq_y.gif&quot; alt=&quot;&quot;&gt; is the absolute difference between the number of clicks for both headlines. The shape of the Anscombe boundary is shown in the figure below. Here, we assumed that the front page gets 1,000 views per minute (VPM). So, after 20 minutes of testing, the front page has been viewed 20,000 times. The figure also shows the absolute difference for five simulated headline tests (CTR A=5%, CTR B=3%), which are denoted by gray lines.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/vr-ht-anscombe.png&quot; alt=&quot;Anscombe Boundary&quot; title=&quot;Anscombe Boundary&quot;&gt;&lt;/p&gt;

&lt;p&gt;The figure illustrates that the Anscombe boundary takes the trade-off between the number of views so far, and the number of views after conclusion into account. In a recent blog post, Aaron Goodman performed an &lt;a href=&quot;http://blog.custora.com/2012/05/a-bayesian-approach-to-ab-testing/&quot;&gt;interesting comparison&lt;/a&gt; between the frequentist, multiple testing, and Bayesian approaches. He demonstrated that the Bayesian approach is best at minimizing regret, or, in other words, maximizing article views.&lt;/p&gt;

&lt;p&gt;Again, once the absolute difference passes the Anscombe boundary, we are ready to conclude which headline was better.&lt;/p&gt;

&lt;h3&gt;Certainty of conclusion&lt;/h3&gt;

&lt;p&gt;It would nice to know with how much certainty we can conclude that one headline is better than the other.&lt;/p&gt;

&lt;p&gt;The certainty associated with the CTRs of Headlines A and B can be modeled by a beta distribution. The beta distribution can be defined in terms of the number of views and CTR as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/eq_beta.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The figure below shows how a beta distribution becomes more peaked as the number of views increases (while keeping the CTR at 20%). It illustrates that as we collect more evidence (i.e., views) our uncertainty about the CTR decreases.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/vr-ht-beta-views-ctr.png&quot; alt=&quot;Parameterizing a beta distribution with views and CTR&quot; title=&quot;Parameterizing a beta distribution with views and CTR&quot;&gt;&lt;/p&gt;

&lt;p&gt;The gray lines may give the impression that the peakedness increases linearly with the number of views, but please note that these lines represent the number of views on a log scale. Allow me to clarify this with the following image, which shows that the interval in which 95% of the probability density is located, i.e., the 95% credibility interval as it is called in Bayesian statistics, decreases exponentially with respect to the number of views.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/vr-ht-credibility-interval.png&quot; alt=&quot;Credibility Interval&quot; title=&quot;Credibility Interval&quot;&gt;&lt;/p&gt;

&lt;p&gt;The amount of overlap between A’s beta distributions and B’s beta distribution determines the certainty of our conclusion. We can estimate this certainty by generating a random value (i.e., drawing a random sample) from both beta distributions and note which value one is higher. If we repeat this, say, a million times, we can accurately estimate the probability that B is better than A. This probability is the certainty with which we can declare headline B as the true winner.&lt;/p&gt;

&lt;p&gt;Instead of estimating the certainty, it can also be computed in closed form &lt;a href=&quot;http://www.johndcook.com/blog/2012/10/11/beta-inequalities-in-r/&quot;&gt;(see this post from John Cook’s blog)&lt;/a&gt;, but the
&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html&quot;&gt;stats.beta.pdf function from scipy&lt;/a&gt; doesn’t like very peaked beta distributions. One of the few exceptions that R is better than python! ;-)&lt;/p&gt;

&lt;p&gt;Below are two figures that show how long it takes to conclude and the amount of certainty associated to that conclusion. In the first figure, the CTRs of both headlines are kept constant (CTR A=5%, CTR B=3%), and the views per minute (VPM) varies from 10 to 10,000. In the second figure, the VPM (=1000) and the CTR of headline A (=5%) are kept constant and the CTR of headline B varies from 0% to 10%.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/vr-ht-time-to-conclude.png&quot; alt=&quot;Time to conclude&quot; title=&quot;Time to conclude&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/vr-ht-certainty.png&quot; alt=&quot;Time to conclude&quot; title=&quot;Time to conclude&quot;&gt;&lt;/p&gt;

&lt;p&gt;In case of sufficient certainty, we declare the headline with the highest CTR as the winner of the headline test. After that, the editor may decide to continue to serve the winning headline to 100% of the readers.&lt;/p&gt;

&lt;p&gt;The serving aspect is actually taken care of by our platform and doesn’t require any additional integration, but that’s material for a blog post that one of our fine front-end engineers should write!&lt;/p&gt;

&lt;h3&gt;Conclusions&lt;/h3&gt;

&lt;p&gt;Visual Revenue’s Instant Headline Testing tool enables editors to A/B test easily different headlines and to quickly see whether the quality has improved. The frequentist approach, which is often used for A/B tests, is unable to overcome the challenges that are associated with A/B testing headlines. The Bayesian approach, however, offers the flexibility that front pages require.&lt;/p&gt;

&lt;p&gt;I have explained how the Bayesian approach, using the Anscombe boundary, determines when the stop a headline test. I also discussed how we can compute the certainty associated with concluding that one headline is better than the other.&lt;/p&gt;

&lt;p&gt;If you would like to play with beta distributions and compute the associated certainty, Peak Conversion provides a nice &lt;a href=&quot;http://www.peakconversion.com/2012/02/ab-split-test-graphical-calculator/&quot;&gt;graphical calculator&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If I still haven’t convinced you that the Bayesian approach is the way to go, then you may want to have a look at: &lt;strong&gt;John A. List, Sally Sadoff, and Mathis Wagner. &lt;em&gt;“So you want to run an experiment, now what? Some Simple Rules of Thumb for Optimal Experimental Design.”&lt;/em&gt; NBER Working Paper No. 15701&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Alternatively, the frequentist approach provides methods that allow for setting up “checkpoints” where you may determine whether you want to stop a headline test. In other words, these methods offer &lt;a href=&quot;http://en.wikipedia.org/wiki/Multiple_comparisons&quot;&gt;correction for multiple testing&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you like what I had to say then you may want to &lt;a href=&quot;https://twitter.com/jeroenhjanssens&quot;&gt;follow me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Sun, 18 Aug 2013 10:00:00 +0000</pubDate>
				<link>http://www.jeroenjanssens.com/2013/08/18/bayesian-headline-testing-at-visual-revenue.html</link>
				<guid isPermaLink="true">http://www.jeroenjanssens.com/2013/08/18/bayesian-headline-testing-at-visual-revenue.html</guid>
			</item>
		
			<item>
				<title>Quickly navigate your filesystem from the command-line</title>
				<description>&lt;p&gt;&lt;em&gt;Update (6-9-2013) This code is now also available as the &amp;quot;jump&amp;quot; plugin in &lt;a href=&quot;https://github.com/robbyrussell/oh-my-zsh&quot;&gt;oh-my-zsh&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Update (18-8-2013): Thanks to the many useful suggestions in &lt;a href=&quot;https://news.ycombinator.com/item?id=6229001&quot;&gt;the discussion on Hacker News&lt;/a&gt;, I have added (1) quotes to the code, (2) a section about tab completion, and (3) a note for Mac OS X users.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Like many others, I spend most of my day behind a computer.
In order make the most of it (and to keep my body from complaining too much), I try to maintain an optimized setup.
For example, I code in &lt;a href=&quot;http://en.wikipedia.org/wiki/Vim_(text_editor)&quot;&gt;Vim&lt;/a&gt;, browse with &lt;a href=&quot;http://www.vimperator.org/vimperator&quot;&gt;Vimperator&lt;/a&gt;, and move windows around in &lt;a href=&quot;http://i3wm.org&quot;&gt;i3&lt;/a&gt;.
Another common task is filesystem navigation. 
I prefer to use the command-line for this, but typing &lt;code&gt;cd ~/some/very/deep/often-used/directory&lt;/code&gt; over and over again does become cumbersome.&lt;/p&gt;

&lt;p&gt;Automated tools like &lt;a href=&quot;https://github.com/joelthelion/autojump&quot;&gt;autojump&lt;/a&gt;, &lt;a href=&quot;https://github.com/rupa/z&quot;&gt;z&lt;/a&gt;, and &lt;a href=&quot;https://github.com/clvv/fasd&quot;&gt;fasd&lt;/a&gt; address this problem by offering shortcuts to the directories you often go to.
Personally, I prefer a more manual solution, which I would like to share with you.
I have noticed quite an increase in efficiency with this, and perhaps you will too.&lt;/p&gt;

&lt;h3&gt;Jumping with symbolic links&lt;/h3&gt;

&lt;p&gt;Under the hood this manual solution comes down to storing symbolic links in a hidden directory (e.g., &lt;code&gt;~/.marks&lt;/code&gt;).
There are four shell functions &lt;code&gt;jump&lt;/code&gt;, &lt;code&gt;mark&lt;/code&gt;, &lt;code&gt;unmark&lt;/code&gt;, and &lt;code&gt;marks&lt;/code&gt;, and they look like this:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;MARKPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.marks
&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;jump &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
    &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; -P &lt;span class=&quot;s2&quot;&gt;&amp;quot;$MARKPATH/$1&amp;quot;&lt;/span&gt; 2&amp;gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;No such mark: $1&amp;quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;mark &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
    mkdir -p &lt;span class=&quot;s2&quot;&gt;&amp;quot;$MARKPATH&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; ln -s &lt;span class=&quot;s2&quot;&gt;&amp;quot;$(pwd)&amp;quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;$MARKPATH/$1&amp;quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;unmark &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
    rm -i &lt;span class=&quot;s2&quot;&gt;&amp;quot;$MARKPATH/$1&amp;quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;marks &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    ls -l &lt;span class=&quot;s2&quot;&gt;&amp;quot;$MARKPATH&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sed &lt;span class=&quot;s1&quot;&gt;&amp;#39;s/  / /g&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; cut -d&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt; -f9- &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sed &lt;span class=&quot;s1&quot;&gt;&amp;#39;s/ -/\t-/g&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Put this in your &lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;.bashrc&lt;/code&gt; and you&amp;#39;re ready to jump (Mac OS X users need a slightly different version of the &lt;code&gt;marks&lt;/code&gt; function; see below). I have also turned this into a plugin for &lt;a href=&quot;https://github.com/robbyrussell/oh-my-zsh&quot;&gt;oh-my-zsh&lt;/a&gt; called &lt;code&gt;jump&lt;/code&gt;. To add a new bookmark, &lt;code&gt;cd&lt;/code&gt; into the directory and &lt;code&gt;mark&lt;/code&gt; it with a name to your liking:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/some/very/deep/often-used/directory
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;mark deep
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This adds a symbolic link named &lt;code&gt;deep&lt;/code&gt; to the directory &lt;code&gt;~/.marks&lt;/code&gt;. To &lt;code&gt;jump&lt;/code&gt; to this directory, type the following from any place in the filesystem:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jump deep
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To remove the bookmark (i.e., the symbolic link), type:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;unmark deep
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can view all marks by typing:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;marks

deep    -&amp;gt; /home/johndoe/some/very/deep/often-used/directory
foo     -&amp;gt; /usr/bin/foo/bar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That&amp;#39;s all there is to it! &lt;/p&gt;

&lt;h3&gt;Adding tab completion&lt;/h3&gt;

&lt;p&gt;In order to add tab completion for the &lt;code&gt;jump&lt;/code&gt; and &lt;code&gt;unmark&lt;/code&gt; functions, add the following code to your .zshrc (thanks to &lt;a href=&quot;https://news.ycombinator.com/item?id=6229468&quot;&gt;tiziano88&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;_completemarks &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;reply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;ls &lt;span class=&quot;nv&quot;&gt;$MARKPATH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

compctl -K _completemarks jump
compctl -K _completemarks unmark
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or the following to your .bashrc (thanks to &lt;a href=&quot;https://news.ycombinator.com/item?id=6229768&quot;&gt;microcolonel&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;_completemarks&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;curw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;COMP_WORDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[COMP_CWORD]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;wordlist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;find &lt;span class=&quot;nv&quot;&gt;$MARKPATH&lt;/span&gt; -type l -printf &lt;span class=&quot;s2&quot;&gt;&amp;quot;%f\n&amp;quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;COMPREPLY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compgen&lt;/span&gt; -W &lt;span class=&quot;s1&quot;&gt;&amp;#39;${wordlist[@]}&amp;#39;&lt;/span&gt; -- &lt;span class=&quot;s2&quot;&gt;&amp;quot;$curw&amp;quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return &lt;/span&gt;0
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;complete&lt;/span&gt; -F _completemarks jump unmark
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you now type &lt;code&gt;jump&lt;/code&gt; or &lt;code&gt;unmark&lt;/code&gt; and then press TAB, you see a list of available marks. Neat!&lt;/p&gt;

&lt;h3&gt;Note for Mac OS X users&lt;/h3&gt;

&lt;p&gt;As pointed out by &lt;a href=&quot;https://news.ycombinator.com/item?id=6229428&quot;&gt;guygurari&lt;/a&gt;, Mac OS X users need a slightly different version of the &lt;code&gt;marks&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;marks &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;se&quot;&gt;\l&lt;/span&gt;s -l &lt;span class=&quot;s2&quot;&gt;&amp;quot;$MARKPATH&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; tail -n +2 &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sed &lt;span class=&quot;s1&quot;&gt;&amp;#39;s/  / /g&amp;#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; cut -d&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt; -f9- &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; awk -F &lt;span class=&quot;s1&quot;&gt;&amp;#39; -&amp;gt; &amp;#39;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;{printf &amp;quot;%-10s -&amp;gt; %s\n&amp;quot;, $1, $2}&amp;#39;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you like what I had to say then you may want to &lt;a href=&quot;https://twitter.com/jeroenhjanssens/&quot;&gt;follow me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Fri, 16 Aug 2013 19:06:19 +0000</pubDate>
				<link>http://www.jeroenjanssens.com/2013/08/16/quickly-navigate-your-filesystem-from-the-command-line.html</link>
				<guid isPermaLink="true">http://www.jeroenjanssens.com/2013/08/16/quickly-navigate-your-filesystem-from-the-command-line.html</guid>
			</item>
		
	</channel>
</rss>
